[
  {
    "objectID": "bayesTPC_activity.html",
    "href": "bayesTPC_activity.html",
    "title": "Introduction to Bayesian Methods",
    "section": "",
    "text": "This section is focused on using the bayesTPC package to fit TPCs to data using the methods we’ve explored in the Bayesian lectures and the first two activities. Here we won’t be talking much about the implementation, but instead will rely on the bayesTPC package and it’s functions to allow us to specify, fit, and analyze the data."
  },
  {
    "objectID": "bayesTPC_activity.html#data-from-vectraits",
    "href": "bayesTPC_activity.html#data-from-vectraits",
    "title": "Introduction to Bayesian Methods",
    "section": "Data from VecTraits",
    "text": "Data from VecTraits\nThe data we want to fit is available on the VecTraits database. We can use the helper function included as part of bayesTPC that isdesigned to interact with this database, get_datasets(), along with the appropriate data set id numbers to retrieve and load them into R.\n\naedes_data &lt;- get_datasets(577:579)\n\nWe have downloaded all three datasets. As always, first we have a look at the data (just looking at a few columns, since the VecTraits format is large so it can hold a lot of different types of information):\n\ncols&lt;-c(2,5,6,9,68)\naedes1&lt;-aedes_data[[3]]\nhead(aedes1[,cols])\n\n  DatasetID OriginalTraitName                        OriginalTraitDef\n1       579         longevity individual-level duration of life stage\n2       579         longevity individual-level duration of life stage\n3       579         longevity individual-level duration of life stage\n4       579         longevity individual-level duration of life stage\n5       579         longevity individual-level duration of life stage\n6       579         longevity individual-level duration of life stage\n  OriginalTraitValue Interactor1Temp\n1                 10              22\n2                  9              22\n3                  7              22\n4                 11              22\n5                 10              22\n6                  6              22\n\n\nTrait data need to be in a particular format before being passed into the fitting routine. Specifically, the data must be stored as a list with names Trait for the modeled response and Temp for the corresponding temperature settings (in ^\\circC, as this is necessary for some of the TPC functions). We format the three datasets here:\n\n# development rate\ndev_rate &lt;- list(Trait = 1/aedes_data[[2]]$OriginalTraitValue,\n                 Temp = aedes_data[[2]]$Interactor1Temp)\n\n# adult longevity\nadult_life &lt;- list(Trait = aedes_data[[3]]$OriginalTraitValue,\n                   Temp = aedes_data[[3]]$Interactor1Temp)\n\n# juvenile survival data\njuv_survival &lt;- list(Trait = aedes_data[[1]]$OriginalTraitValue,\n                     Temp = aedes_data[[1]]$Interactor1Temp)\n\nNotice that we follow a convention here treating the development rate as 1/development time. This is a common assumption (although it is formally only valid if we believe that development times are exponentially distributed). Often mathematical models assume exponentially distributed traits, and so this is why the data are modeled in this fashion. We will show this approach here, as it is common, but do not advocate for this in general.\n\n\n\n\n\n\n\n\nFigure 1: Three example datasets from @huxley2022competition: Development Rate, Adult Longevity, and Juvenile Survival. Temperatures for the juvenile survival data are jittered for visibility\n\n\n\n\n\nWe will first go through a case where the default settings give reasonable output out of the box (adult lifespan) in order to show basic functions in action. We then approach a case where the defaults need to be modified (development rate). As part of your independent practice, you can fit data (juvenile survival) where we would use a glm model for the data."
  },
  {
    "objectID": "bayesTPC_activity.html#inference-with-default-settings",
    "href": "bayesTPC_activity.html#inference-with-default-settings",
    "title": "Introduction to Bayesian Methods",
    "section": "Inference with default settings",
    "text": "Inference with default settings\nOnce we have the data formatted as required by b_TPC(), we can fit each of the datasets with a single call, using the default settings. As we saw in the plot above, adult lifespan are numeric data where a concave down unimodal response is likely appropriate. For adult lifespan, we chose to fit a Briere function with the default specification:\n\nget_default_model_specification(\"briere\")\n\nbayesTPC Model Specification of Type:\n  briere\n\nModel Formula:\n  m[i] &lt;- ( q * Temp * (Temp - T_min) * sqrt((T_max &gt; Temp) * abs(T_max - Temp))\n* (T_max &gt; Temp) * (Temp &gt; T_min) )\n\nModel Distribution:\nTrait[i] ~ T(dnorm(mean = m[i], tau = 1/sigma.sq), 0, )\n\nModel Parameters and Priors:\n  q ~ dunif(0, 1) \n  T_max ~ dunif(25, 60) \n  T_min ~ dunif(0, 24)\n\nPrior for Variance:\n  sigma.sq ~ dexp(1)\n\n\nTo fit the model then requires a single line of code with the first argument being the name of the formatted data object and the second being the name of the TPC that we want to use for fitting. By default we take 10000 samples, no burn-in, using a random walk sampler.\n\nadult_life_fit &lt;- b_TPC(adult_life, \"briere\")\n\nOnce the fitting process has completed (which can take a few minutes), we can have a gander at the fitted model object using print. This command provides details about the model fit, the priors, and some simple summaries of the fitted model.\n\nprint(adult_life_fit)\n\nbayesTPC MCMC of Type:\n  briere\n\nFormula:\n  m[i] &lt;- ( q * Temp * (Temp - T_min) * sqrt((T_max &gt; Temp) * abs(T_max - Temp))\n* (T_max &gt; Temp) * (Temp &gt; T_min) )\n\nDistribution:\nTrait[i] ~ T(dnorm(mean = m[i], tau = 1/sigma.sq), 0, )\n\nParameters:\n            MAP   Mean Median        Priors\nT_max    34.465 28.764 27.509 dunif(25, 60)\nT_min     0.035 10.882 12.537  dunif(0, 24)\nq         0.005  0.029  0.017   dunif(0, 1)\nsigma.sq 16.672 34.742 38.450       dexp(1)\n\n\nWe can also see what is in the object:\n\nnames(adult_life_fit)\n\n[1] \"samples\"        \"mcmc\"           \"data\"           \"model_spec\"    \n[5] \"priors\"         \"constants\"      \"uncomp_model\"   \"comp_model\"    \n[9] \"MAP_parameters\"\n\n\nMost of what we do relies on the “samples” portion of the object, although bayesTPC has helper functions to reduce the need to interact with these directly in most cases."
  },
  {
    "objectID": "bayesTPC_activity.html#mcmc-diagnotic-plots",
    "href": "bayesTPC_activity.html#mcmc-diagnotic-plots",
    "title": "Introduction to Bayesian Methods",
    "section": "MCMC Diagnotic Plots",
    "text": "MCMC Diagnotic Plots\nb_TPC() returns an object of class btpc_MCMC which contains (along with model specification information and data) the MCMC samples as an mcmc object from the package coda. As mentioned in the previous portion of the training, it is important to check the MCMC traceplot before using or interpreting a fitted model to ensure the chains have converged. An MCMC traceplot shows each sample for a parameter in the order that the samples were taken. If the model has converged, the traceplot will eventually start varying around a single point, resembling a “fuzzy caterpillar”.\n\npar(mfrow=c(2,2), mar=c(4,3,3,1)+.1)\ntraceplot(adult_life_fit)\n\n\n\n\n\n\n\nFigure 2: Traceplots for the three parameters of the Briere TPC and the observation parameter for model fitted to the Adult Longevity data.\n\n\n\n\n\nWe notice that it takes a while for the chains to converge. Thus we need to specify a burn-in period and only consider samples obtained after the burn-in. For this example, a burn-in of around 3000 should give us a good result. We can re-visualize with this burn-in (by adding burn=3000 as an argument to traceplot):\n\npar(mfrow=c(2,2), mar=c(4,3,3,1)+.1)\nmyburn&lt;-3000\ntraceplot(adult_life_fit, burn=myburn)\n\n\n\n\n\n\n\nFigure 3: Traceplots for the three parameters of the Briere TPC and the observation parameter for model fitted to the Adult Longevity data. Here the burn-in portion of the MCMC chains has been dropped.\n\n\n\n\n\nThis is much better! All of the chains now have the desired “fuzzy caterpillar” look. Typically one would at this point go back to the original fitting function, and specify the burn-in time, along with potentially increasing the total sample size in order to ensure sufficient samples. This approach drops the burnin samples from the returned object. For brevity herewe will simply specify the value of burn as an argument for the remaining plotting functions.\nWe can examine the ACF of the chains as well (one for each parameter), similarly to a time series, to again check for autocorrelation within the chain (we want the autocorrelation to be fairly low):\n\ns1&lt;-as.data.frame(adult_life_fit$samples[myburn:10000,])\npar(mfrow=c(2,2), bty=\"n\", mar=c(4,4,3,1)+.1)\nfor(i in 1:4) {\n  acf(s1[,i], lag.max=50, main=\"\",\n      ylab = paste(\"ACF: \", names(s1)[i], sep=\"\"))\n}\n\n\n\n\n\n\n\n\nThere is still autocorrelation, especially for two of the quadratic parameters. The chain for \\sigma is mixing best (the ACF falls off the most quickly). We could reduce the autocorrelation even further by thinning the chain (i.e., change the nt parameter to 5 or 10), or changing the type of sampler.\nA second important diagnostic step is to compare the marginal priors and posteriors of our model parameters. This enables us to confirm that (unless we’ve purposefully specified an informative prior) that our posterior distributions have been informed by the data. bayesTPC includes a built in function, ppo_plot(), that creates posterior/prior overlap plots for all model parameters (note that the priors are smoothed because the algorithm uses kernel smoothing instead of the exact distribution).\n\npar(mfrow=c(2,2), mar=c(4,3,3,1)+.1)\nppo_plot(adult_life_fit, burn=myburn, legend_position = \"topright\")\n\n\n\n\n\n\n\nFigure 4: Marginal prior/posterior for the three parameters of the Briere TPC and the observation parameter for the model fitted to the Adult Longevity data. Note that the burn-in is dropped for these plots using the burn argument.\n\n\n\n\n\nThe prior distribution here is very different from the posterior. These data are highly informative for the parameters of interest and are very unlikely to be influenced much by the prior distribution (although you can always change the priors to check this). However, notice that the posterior T_0 is slightly truncated by their priors. If priors and posteriors are very similar one should shift the priors, and re-run."
  },
  {
    "objectID": "bayesTPC_activity.html#additional-plotting",
    "href": "bayesTPC_activity.html#additional-plotting",
    "title": "Introduction to Bayesian Methods",
    "section": "Additional plotting",
    "text": "Additional plotting\nAfter we have established appropriate burn-in values, we can use plot(), posterior_predictive(), and plot_prediction() to examine the fit of the model in two ways. The defaults for the plot() function plots the median and 95% Highest Posterior Density (HPD) interval of the fitted function (i.e., plugging the samples into the TPC function, and calculating the median and HPD interval at all evaluated temperatures). In contrast, the posterior_predictive() function uses simulation to draw points from the posterior predictive distribution, and so it includes both the samples describing the TPC function and the observational model. It then uses these samples to calculate the mean/median and the HPD interval of those simulated points. Both kinds of plots are shown in Figure 5 for comparison.\n\n\n\n\n\n\n\n\nFigure 5: Comparison of the plots produced by the plot() function (LEFT) and the combination of the posterior_predictive(), and plot_prediction() functions (RIGHT). By default both functions would only make plots/predictions within the range of temperatures included in the fitted data. However here we show the use of the temp_interval argument to enable plotting of predictions across a broader temperature range.\n\n\n\n\n\nNote that the two bottom fits show different output. On the left we show the HPD bounds and median of the fitted Briere function, only. On the right, in contrast, shows the bounds and mean/median of the posterior predictive distribution (so it includes the randomness that is part of the truncated normal observation model). Notice that the HPD predictive interval is a bit jagged here. These intervals are generated using sampling from the posterior predictive distribution. Increasing the total number of samples can give smoother bounds in general.\nNow that we’ve confirmed that things are working well, it’s often useful to also look at the joint distribution of all of your parameters together to understand how estimates are related to each other. Of course, if you have a high dimensional posterior, rendering a 2-D representation can be difficult. The standard is to examine the pair-wise posterior distribution. We can do this using the function bayesTPC_ipairs():\n\nbayesTPC_ipairs(adult_life_fit, burn=myburn)\n\n\n\n\n\n\n\nFigure 6: Pairwise visualization of the joint posterior distribution of parameters for the three parameters of the Briere TPC and the observation parameter for the model fitted to the Adult Longevity data. Note that the burn-in is dropped for this plot using the burn argument.\n\n\n\n\n\nNotice that there is substantial correlation between q and T_{min} (a.k.a., T_0). This is typical for most TPCs, and is one of the reasons why prior choice can be very important!"
  },
  {
    "objectID": "bayesTPC_activity.html#summaries",
    "href": "bayesTPC_activity.html#summaries",
    "title": "Introduction to Bayesian Methods",
    "section": "Summaries",
    "text": "Summaries\nIf we are satisfied with the traceplots, fits, and prior/posterior plots, users may want to examine additional summary output (for example to make tables) or to save summaries. Numerical summaries are available through the print() function shown above, but we can see more details using summary().\n\nsummary(adult_life_fit, burn=myburn)\n\nbayesTPC MCMC of Type:\n  briere\n\nFormula:\n  m[i] &lt;- ( q * Temp * (Temp - T_min) * sqrt((T_max &gt; Temp) * abs(T_max - Temp))\n* (T_max &gt; Temp) * (Temp &gt; T_min) )\n\nDistribution:\nTrait[i] ~ T(dnorm(mean = m[i], tau = 1/sigma.sq), 0, )\n\nPriors:\n  q ~ dunif(0, 1) \n  T_max ~ dunif(25, 60) \n  T_min ~ dunif(0, 24) \n  sigma.sq ~ dexp(1)\n\nMax. A Post. Parameters: \n     T_max      T_min          q   sigma.sq   log_prob \n   34.4652     0.0350     0.0048    16.6718 -1925.8788 \n\nMCMC Results:\nIterations = 1:10000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n             Mean     SD Naive SE Time-series SE\nT_max    28.76360 2.9406 0.029406       1.654002\nT_min    10.88169 6.9010 0.069010       2.372677\nq         0.02861 0.0392 0.000392       0.006959\nsigma.sq 34.74219 9.2907 0.092907       3.296142\n\n2. Quantiles for each variable:\n\n              2.5%       25%      50%      75%   97.5%\nT_max    26.155854 26.800453 27.50899 28.82192 34.5667\nT_min     0.229460  3.649167 12.53726 17.13245 20.5203\nq         0.004798  0.007817  0.01668  0.03479  0.1243\nsigma.sq 15.776652 35.975053 38.44992 40.43169 43.6787\n\n\nWe may want to store some of the sample statistics for later use. The sample-based Maximum a posteriori (MAP) estimator is calculated and saved as part of our fitting process, and can be obtained directly from the fit object.\n\n# MAP estimator\nadult_life_fit$MAP_parameters |&gt; round(5)\n\n      T_max       T_min           q    sigma.sq    log_prob \n   34.46524     0.03496     0.00478    16.67180 -1925.87878 \n\n\nThe other sample statistics for each parameter can be obtained by saving the summary of the samples in the fitted model object. Then the various statistics may be extracted directly:\n\nestimates &lt;- summary(adult_life_fit$samples)\n\n# Mean\nestimates$statistics[,\"Mean\"]\n\n      T_max       T_min           q    sigma.sq \n28.76360399 10.88169080  0.02861184 34.74219459 \n\n# Median and 95% CI bounds\nestimates$quantiles[,c(\"2.5%\", \"50%\", \"97.5%\")]\n\n                 2.5%         50%      97.5%\nT_max    26.155853717 27.50898620 34.5666961\nT_min     0.229460133 12.53725788 20.5203034\nq         0.004798289  0.01667521  0.1243185\nsigma.sq 15.776651741 38.44992386 43.6787004\n\n\nIf one instead would like the Highest Posterior Density bounds (instead of the quantile based summaries) the HPDinterval function from coda may be used.\n\nHPDinterval(adult_life_fit$samples)\n\n                lower      upper\nT_max    26.154094855 34.5616431\nT_min     0.258472850 20.5338334\nq         0.004628949  0.1088912\nsigma.sq 15.728537710 43.5531210\nattr(,\"Probability\")\n[1] 0.95"
  },
  {
    "objectID": "bayesTPC_activity.html#fitting-with-default-settings",
    "href": "bayesTPC_activity.html#fitting-with-default-settings",
    "title": "Introduction to Bayesian Methods",
    "section": "Fitting with default settings",
    "text": "Fitting with default settings\nThe default priors chosen in bayesTPC are generally as non-restrictive as possible, which can lead to inappropriate fits when the response trait is very close to zero. In this case it may be necessary to modify the priors. It is also possible that mixing may be poor with the default sampler, and so we may need to update the sampling method. We briefly show these issues using the development rate data as an example. These data are also numeric and we assume, again, a Briere functional response:\n\ndev_rate_fit &lt;- b_TPC(dev_rate, \"briere\")\n\nHowever in this case, although the traceplots look ok (after a burnin) the fits are very poor (Figure 7)\n\n\n\n\n\n\n\n\nFigure 7: Traceplots for the three parameters of the Briere TPC and the observation parameter for model fitted to the juvenile development data. (top 4 panels) with the data (bottom left) and corresponding posterior predictive (bottom right) plots based on these samples. The burn-in portion of the MCMC chains has been dropped.\n\n\n\n\n\nWe can see a bit of what is going on by looking at the marginal prior/posterior plots:\n\npar(mfrow=c(2,2), mar=c(4,3,3,1)+.1)\nppo_plot(dev_rate_fit, burn=myburn, legend_position = \"topright\")\n\n\n\n\n\n\n\nFigure 8: Marginal prior/posterior for the three parameters of the Briere TPC and the observation parameter for the model fitted to the Juvenile development rate data. Note that the burn-in is dropped for these plots using the burn argument.\n\n\n\n\n\nHere the posterior for q is effectively the same as the prior, and both T_{min} and T_{max} are bumping up against the edges of their ranges."
  },
  {
    "objectID": "bayesTPC_activity.html#changing-fitting-arguments",
    "href": "bayesTPC_activity.html#changing-fitting-arguments",
    "title": "Introduction to Bayesian Methods",
    "section": "Changing Fitting arguments",
    "text": "Changing Fitting arguments\nIn order to try to improve the fitting, we will modify the priors and the sampler. We notice from the plot of the data that the rate seems to increase across the observed range of the data. Thus it is likely that the T_{\\mathrm{max}} parameter is at or above the temperature manipulated in the experiment and T_{\\mathrm{min}} is below. We can pass this information in as new priors through the priors argument as shown. Further, we can switch to a sampler that has a better chance of converging by modifying the samplerType parameter. Here, we use automated factor slice sampling. Although this sampler is often more effective (especially when parameters are highly correlated, as they are for most TPCs), it is slower and so is not used by default. These changes result in much better fits (see Figure 9).\n\ndev_rate_fit2 &lt;- b_TPC(dev_rate, \"briere\",\n                       priors = list(T_min = \"dunif(0,22)\",\n                                     T_max = \"dunif(34,50)\"),\n                       burn=myburn,\n                       samplerType = \"AF_slice\")\n\n\n\n\n\n\n\n\n\nFigure 9: Traceplots for the three parameters of the Briere TPC and the observation parameter for the model fitted to the juvenile development data (top 4 panels) with the corresponding summary (bottom left) and posterior predictive (bottom right) plots based on these samples. The burn-in portion of the MCMC chains has been dropped as part of the fitting.\n\n\n\n\n\nThis is much better! The chains mix well, and our predictions now lie along with the data. If you were to plot the autocorrelation you would notice that it falls off much more quickly."
  },
  {
    "objectID": "bayesTPC_activity.html#model-selection",
    "href": "bayesTPC_activity.html#model-selection",
    "title": "Introduction to Bayesian Methods",
    "section": "Model Selection",
    "text": "Model Selection\nWhat if we didn’t know that the Briere was the preferred model for these development rate data? We can fit with another function, check all of the diagnostics, and then compare via WAIC (Widely Applicable Information Criterion) to choose between them. For the juvenile development rate, let’s try a quadratic. Let’s look at the implementation details:\n\nget_formula(\"quadratic\")\n\nexpression(-1 * q * (Temp - T_min) * (Temp - T_max) * (T_max &gt; \n    Temp) * (Temp &gt; T_min))\n\n\n\nget_default_priors(\"quadratic\")\n\n              q           T_max           T_min \n  \"dunif(0, 1)\" \"dunif(25, 60)\"  \"dunif(0, 24)\" \n\n\nI will refit using the default priors, except for the prior for q (so you can see an option):\n\ndev_rate_fit_Quad &lt;- b_TPC(data = dev_rate, ## data\n                           model = 'quadratic', ## model to fit\n                           niter = 10000, ## total iterations\n                           burn = 3000, ## number of burn in samples\n                           samplerType = 'AF_slice', ## slice sampler\n                           priors = list(q = 'dexp(1)') ## priors\n                    ) \n\nCreating NIMBLE model:\n - Configuring model.\n - Compiling model.\n\nCreating MCMC:\n - Configuring MCMC.\n - Compiling MCMC.\n - Running MCMC.\n\nProgress:\n|-------------|-------------|-------------|-------------|\n|-------------------------------------------------------|\n\nConfiguring Output:\n - Finding Max. a Post. parameters.\n\n\n\nsummary(dev_rate_fit_Quad)\n\nbayesTPC MCMC of Type:\n  quadratic\n\nFormula:\n  m[i] &lt;- ( -1 * q * (Temp - T_min) * (Temp - T_max) * (T_max &gt; Temp) * (Temp &gt;\nT_min) )\n\nDistribution:\nTrait[i] ~ T(dnorm(mean = m[i], tau = 1/sigma.sq), 0, )\n\nPriors:\n  q ~ dexp(1) \n  T_max ~ dunif(25, 60) \n  T_min ~ dunif(0, 24) \n  sigma.sq ~ dexp(1)\n\nMax. A Post. Parameters: \n   T_max    T_min        q sigma.sq log_prob \n 27.2762  23.4034   0.0102   0.0128 985.5949 \n\nMCMC Results:\nIterations = 1:7000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 7000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n             Mean        SD  Naive SE Time-series SE\nT_max    25.80008 0.5127068 6.128e-03        0.05132\nT_min    23.02759 0.5877694 7.025e-03        0.01959\nq         0.69929 0.9417656 1.126e-02        0.04569\nsigma.sq  0.01349 0.0009306 1.112e-05        0.00003\n\n2. Quantiles for each variable:\n\n              2.5%      25%      50%      75%    97.5%\nT_max    25.037709 25.39160 25.80821 26.07444 27.29098\nT_min    22.044379 22.51433 23.04794 23.54120 23.95935\nq         0.008079  0.08584  0.33621  0.94822  3.31108\nsigma.sq  0.011661  0.01286  0.01351  0.01413  0.01528\n\n\nWe again plot the chains of the three main TPC parameters and the standard deviation of the normal observation model:\n\n\n\n\n\n\n\n\nFigure 10: Traceplots for the three parameters of the quadratic TPC and the observation parameter for the model fitted to the juvenile development data (top 4 panels) with the corresponding summary (bottom left) and posterior predictive (bottom right) plots based on these samples. The burn-in portion of the MCMC chains has been dropped.\n\n\n\n\n\nOnce fitted, we want to be able to choose which of these models is best for these data. Although, a priori we would expect the Briere fit to be best development rates, both fits seem visually reasonable. We can extract the the values of the wAIC [@watanabe2009algebraic] to compare the performance of our models using get_WAIC() (which wraps nimble’s getWAIC() function and produces a tidier format). The preferred model will be the one with the lowest wAIC value. Note that because this is based on samples, you want to have the same number of samples in the chains for each of the models you are comparing.\n\nbayesTPC::get_WAIC(dev_rate_fit2)\n\n        WAIC         lppd        pWAIC \n-3731.667316  1870.386243     4.552585 \n\nbayesTPC::get_WAIC(dev_rate_fit_Quad)\n\n         WAIC          lppd         pWAIC \n-1979.3795635   990.0311345     0.3413528 \n\n\nIn this case the WAIC for the Briere fit is more negative and so is the preferred model."
  },
  {
    "objectID": "bayesTPC_activity.html#practice-option-1",
    "href": "bayesTPC_activity.html#practice-option-1",
    "title": "Introduction to Bayesian Methods",
    "section": "Practice Option 1",
    "text": "Practice Option 1\nFor the Aedes aegypti life span data, try to fit 3 TPC functional forms (Briere, quadratic, and Stinner) to the data. Use slice sampling for all three of them, and make the chains a bit longer (say 15000 plus the 3000 burnin). Check all of the diagnostics for all models, and plot the fits. Then compare the three models via WAIC. Which one comes out on top."
  },
  {
    "objectID": "bayesTPC_activity.html#practice-option-2",
    "href": "bayesTPC_activity.html#practice-option-2",
    "title": "Introduction to Bayesian Methods",
    "section": "Practice Option 2",
    "text": "Practice Option 2\nYou can download some other trait data from the VectorByte – VecTraits Databases or use your own data. Write you own analysis as an independent, self-sufficient R script that produces all the plots in a reproducible workflow when sourced. Use the appropriate functional forms for your data."
  },
  {
    "objectID": "bayesTPC_activity.html#practice-option-3",
    "href": "bayesTPC_activity.html#practice-option-3",
    "title": "Introduction to Bayesian Methods",
    "section": "Practice Option 3",
    "text": "Practice Option 3\nIn addition to the two datasets that we explored here, we downloaded data on juvenile survival. These data are encoded as zeros and ones, and are more appropriately modeled using a Bernoulli/Binomial distribution – that is as GLMs. bayesTPC has implemented two options for fitting these models, either a linear or quadratic:\n\n## Linear:\nget_default_model_specification(\"bernoulli_glm_lin\")\n\nbayesTPC Model Specification of Type:\n  bernoulli_glm_lin\n\nModel Formula:\n  logit(m[i]) &lt;- ( B0 + B1 * Temp )\n\nModel Distribution:\nTrait[i] ~ dbern(m[i])\n\nModel Parameters and Priors:\n  B0 ~ dnorm(0, 500) \n  B1 ~ dnorm(0, 500)\n\n\n\n## Quadratic:\nget_default_model_specification(\"bernoulli_glm_quad\")\n\nbayesTPC Model Specification of Type:\n  bernoulli_glm_quad\n\nModel Formula:\n  logit(m[i]) &lt;- ( B0 + B1 * Temp + B2 * (Temp)^2 )\n\nModel Distribution:\nTrait[i] ~ dbern(m[i])\n\nModel Parameters and Priors:\n  B0 ~ dnorm(0, 500) \n  B1 ~ dnorm(0, 500) \n  B2 ~ dnorm(0, 500)\n\n\nFit the juvenile survival data using both of these models. Note that the slice sampler is typically better for these, and you will likely need a longer chain and more burn-in. Make sure to use the same number of samples/burn-in for both models. Check all the diagnostic plots and plot the data with the fits. Then use WAIC to choose between the two model variants. What do you conclude?"
  },
  {
    "objectID": "VB_Bayes2.html#learning-objectives",
    "href": "VB_Bayes2.html#learning-objectives",
    "title": "VectorByte Methods Training",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nIntroduce computation tools to perform inference for simple models in R (how to turn the Bayesian crank)\nAppreciate the need for sensitivity analysis, model checking and comparison, and the potential dangers of Bayesian methods."
  },
  {
    "objectID": "VB_Bayes2.html#what-if-we-cant-calculate-an-analytic-posterior",
    "href": "VB_Bayes2.html#what-if-we-cant-calculate-an-analytic-posterior",
    "title": "VectorByte Methods Training",
    "section": "What if we can’t calculate an analytic posterior?",
    "text": "What if we can’t calculate an analytic posterior?\nIf we go back to the full Bayes theorem: \\[\n\\text{Pr}(\\theta|Y) = \\frac{\\mathcal{L}(\\theta; Y)f(\\theta)}{\\text{Pr}(Y)}\n\\] We are usually specifying the likelihood and the prior but we often don’t know the normalizing constant in the denominator. Without this, the probabilities don’t properly integrate to 1 and we can’t make probability statements.\nWe can use Monte Carlo methods to approximate the posterior."
  },
  {
    "objectID": "VB_Bayes2.html#stochastic-simulation-monte-carlo",
    "href": "VB_Bayes2.html#stochastic-simulation-monte-carlo",
    "title": "VectorByte Methods Training",
    "section": "Stochastic Simulation & Monte Carlo",
    "text": "Stochastic Simulation & Monte Carlo\nStochastic simulation is a way to understand variability in a system and for calculating quantities that may be difficult or impossible to obtain directly.\n\nMonte Carlo (MC) methods are “a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results.” - Wikipedia"
  },
  {
    "objectID": "VB_Bayes2.html#mc-for-bayesian-statistics",
    "href": "VB_Bayes2.html#mc-for-bayesian-statistics",
    "title": "VectorByte Methods Training",
    "section": "MC for Bayesian Statistics",
    "text": "MC for Bayesian Statistics\nWe use Monte Carlo (MC) methods to generate random deviates in the right ratios from the target posterior called draws or samples.\n\nWe use these draws to approximate/summarize our distribution and make inference statements (point estimates, CIs, etc). We can also use the draws to calculate the posterior distribution of any function of our estimated parameters.\n\nAs the number of draws/samples gets large we can approximate these quantities arbitrarily high precision."
  },
  {
    "objectID": "VB_Bayes2.html#the-plug-in-principle",
    "href": "VB_Bayes2.html#the-plug-in-principle",
    "title": "VectorByte Methods Training",
    "section": "The “plug-in principle”",
    "text": "The “plug-in principle”\nUsing MC to perform these calculations (and to propagate the uncertainty) rests on the idea of the plug-in principle:\n\nA summary statistic or other feature of a distribution (e.g. expected value) can be approximated by the same summary/feature of an empirical sample from that distribution (e.g., sample mean)."
  },
  {
    "objectID": "VB_Bayes2.html#markov-chain-mc-mcmc",
    "href": "VB_Bayes2.html#markov-chain-mc-mcmc",
    "title": "VectorByte Methods Training",
    "section": "Markov Chain MC (MCMC)",
    "text": "Markov Chain MC (MCMC)\nMCMC is the most commonly used numerical algorithm for generating posterior samples.\n A Markov Chain is a sequence of randomly generated numbers where each draw depends on the one immediately preceding it.\n\nPlot – Ian Murray (http://mlg.eng.cam.ac.uk/zoubin/tut06/mcmc.pdf)"
  },
  {
    "objectID": "VB_Bayes2.html#gibbs-sampling",
    "href": "VB_Bayes2.html#gibbs-sampling",
    "title": "VectorByte Methods Training",
    "section": "Gibbs Sampling",
    "text": "Gibbs Sampling\nGibbs sampling is a type of MCMC that leverages the conditional distributions of parameters to generate samples by proposing them one at a time. This is the algorithm implemented in the popular Bayesian packages BUGS, WinBUGS, \\({\\tt nimble}\\), and JAGS/\\({\\tt rjags}\\), and that we use for \\({\\tt bayesTPC}\\).\n We will treat Gibbs sampling and other of the numerical methods as mostly “black boxes”. We’ll learn to diagnose output from these later on in the practical component."
  },
  {
    "objectID": "VB_Bayes2.html#what-do-we-do-with-posterior-samples",
    "href": "VB_Bayes2.html#what-do-we-do-with-posterior-samples",
    "title": "VectorByte Methods Training",
    "section": "What do we do with Posterior Samples?",
    "text": "What do we do with Posterior Samples?\nWe can treat the draws much like we would data:\n\nCalculate posterior summaries (mean, median, mode, etc) just like we would a data sample\nCalculate precision of the summaries (e.g., sample variance)\nCIs via quantiles (order statistics of the data) or HPD intervals (using \\({\\tt CODA}\\) package in \\({\\tt R}\\))\n\n\nIf the samples are parameters in a complex model, we can plug them all in, one at a time, to get a range of possible predictions from the model (we’ll see this in the practical bit, later on)."
  },
  {
    "objectID": "VB_Bayes2.html#models-comparison-via-dic",
    "href": "VB_Bayes2.html#models-comparison-via-dic",
    "title": "VectorByte Methods Training",
    "section": "Models Comparison via (DIC)",
    "text": "Models Comparison via (DIC)\nThe  Deviance Information Criterion (DIC) seeks to judge a model on how well it fits, penalized by the complexity of the model: \\[\nDIC = D(\\bar{\\theta}) + 2p_D\n\\] where:\n\nDeviance: \\(D(\\theta)=-2\\log(\\mathcal{L}(\\theta; y)) + C\\)\nPenalty: \\(p_D = \\bar{D} -D(\\bar{\\theta})\\)\n\\(D(\\bar{\\theta})\\): deviance at the posterior mean of \\(\\theta\\)\n\\(\\bar{D}\\): average deviance across the posterior samples.\n\n\\(\\rightarrow\\) Already implemented in nimble!"
  },
  {
    "objectID": "VB_Bayes2.html#bayesian-using-nimblejags",
    "href": "VB_Bayes2.html#bayesian-using-nimblejags",
    "title": "VectorByte Methods Training",
    "section": "Bayesian using nimble/JAGS",
    "text": "Bayesian using nimble/JAGS\nBoth nimble and JAGS implement Gibbs sampling/MCMC in a fairly easy to use package that you can call from R. Models are encoded using the BUGS language.\n\nThat is, once you specify the appropriate sampling distribution/likelihood and any priors for the parameters, it will use MCMC to obtain samples from the posterior in the right ratios so that we can calculate whatever we want."
  },
  {
    "objectID": "VB_Bayes2.html#specifying-a-bugs-model",
    "href": "VB_Bayes2.html#specifying-a-bugs-model",
    "title": "VectorByte Methods Training",
    "section": "Specifying a BUGS model",
    "text": "Specifying a BUGS model\nThe trickiest and most important part of each analysis is properly specifying the model for all of the data that you want to fit. Before you begin to code, you need to decide:\n\n\nWhat is the relationship between your predictors and your response?\nWhat kind of probability distribution should you use to describe your response variable?\nAre there any constraints on your parameters or responses that you need to encode in your prior or likelihood, respectively?"
  },
  {
    "objectID": "VB_Bayes2.html#next-steps",
    "href": "VB_Bayes2.html#next-steps",
    "title": "VectorByte Methods Training",
    "section": "Next Steps",
    "text": "Next Steps\nThere are two practicals focusing on using \\({\\tt nimble}\\) and \\({\\tt bayesTPC}\\) to conduct analyses. It has two main chunks:\n\nComparing your conjugate Bayesian analysis on the midge data to the approximate results with \\({\\tt nimble}\\).\nFitting a TPC to trait data using \\({\\tt bayesTPC}\\) (easier than having to code it yourself in \\({\\tt nimble}\\)!).\n\nFor both you’ll be led through visualizing your MCMC chains and your posterior distributions of parameters and predictions. There are also advanced practice suggestions for those who want to go further."
  },
  {
    "objectID": "Stats_review_soln.html",
    "href": "Stats_review_soln.html",
    "title": "VectorByte Methods Training 2023",
    "section": "",
    "text": "Main materials\nBack to stats review\n\nQuestion 1: For the six-sided fair die, what is f_k if k=7? k=1.5?\n\nAnswer: both of these are zero, because the die cannot take these values.\n    \n\n\nQuestion 2: For the fair 6-sided die, what is F(3)? F(7)? F(1.5)?\nAnswer: The CDF total probability of having a value less than or equal to its argument. Thus F(3)= 1/2, F(7)=1, and F(1.5)=1/6\n    \n\n\nQuestion 3: For a normal distribution with mean 0, what is F(0)?\n\nAnswer: The normal distribution is symmetric around its mean, with half of its probability on each side. Thus, F(0)=1/2\n    \n\n\nQuestion 4: Summation Notation Practice\n\n\n\ni\n1\n2\n3\n4\n\n\n\n\nZ_i\n2.0\n-2.0\n3.0\n-3.0\n\n\n\n\nCompute \\sum_{i=1}^{4}{z_i} = 0 \nCompute \\sum_{i=1}^4{(z_i - \\bar{z})^2} = 26 \nWhat is the sample variance? Assume that the z_i are i.i.d.. Note that i.i.d.~stands for “independent and identically distributed”. \n\nSolution: \ns^2= \\frac{\\sum_{i=1}^N(Y_i - \\bar{Y})^2}{N-1} = \\frac{26}{3}\n= 8\\times \\frac{2}{3}\n \n\nFor a general set of N numbers, \\{X_1, X_2, \\dots, X_N \\} and \\{Y_1, Y_2, \\dots, Y_N \\} show that \n\\sum_{i=1}^N{(X_i - \\bar{X})(Y_i - \\bar{Y})} = \\sum_{i=1}^N{(X_i-\\bar{X})Y_i}\n\n\n Solution: First, we multiply through and distribute: \n\\sum_{i=1}^N(X_i-\\bar{X})(Y_i-\\bar{Y}) = \\sum_{i=1}^N(X_i-\\bar{X})Y_i\n- \\sum_{i=1}^N(X_i-\\bar{X})\\bar{Y}\n Next note that \\bar{Y} (the mean of the Y_is) doesn’t depend on i so we can pull it out of the summation: \n\\sum_{i=1}^N(X_i-\\bar{X})(Y_i-\\bar{Y}) = \\sum_{i=1}^N(X_i-\\bar{X})Y_i\n- \\bar{Y} \\sum_{i=1}^N(X_i-\\bar{X}).\n Finally, the last sum must be zero because \n\\sum_{i=1}^N(X_i-\\bar{X}) = \\sum_{i=1}^N X_i- \\sum_{i=1}^N \\bar{X} = N\\bar{X} - N\\bar{X}=0.\n Thus \\begin{align*}\n\\sum_{i=1}^N(X_i-\\bar{X})(Y_i-\\bar{Y}) &= \\sum_{i=1}^N(X_i-\\bar{X})Y_i - \\bar{Y}\\times 0\\\\\n& = \\sum_{i=1}^N(X_i-\\bar{X})Y_i.\n\\end{align*}\n    \n\n\nQuestion 5: Properites of Expected Values\nUsing the definition of an expected value above and with X and Y having the same probability distribution, show that:\n\\begin{align*}\n\\text{E}[X+Y]  & = \\text{E}[X] + \\text{E}[Y]\\\\  \n& \\text{and} \\\\\n\\text{E}[cX]  & = c\\text{E}[X]. \\\\\n\\end{align*}\nGiven these, and the fact that \\mu=\\text{E}[X], show that:\n\\begin{align*}\n\\text{E}[(X-\\mu)^2]  = \\text{E}[X^2] - (\\text{E}[X])^2\n\\end{align*}\nThis gives a formula for calculating variances (since \\text{Var}(X)= \\text{E}[(X-\\mu)^2]).\nSolution: Assuming X and Y are both i.i.d. with distribution f(x). The expectation of X+Y is defined as \\begin{align*}\n\\text{E}[X+Y]  & =  \\int (X+Y) f(x)dx \\\\\n              & =  \\int (X f(x) +Y f(x))dx  \\\\\n              & =  \\int X f(x)dx  +\\int Y f(x)dx  \\\\\n               & = \\text{E}[X] + \\text{E}[Y]  \n\\end{align*} Similarly \\begin{align*}\n\\text{E}[cX]   & =  \\int cXf(x)dx \\\\\n              & =  c \\int Xf(x) dx  \\\\\n              & = c\\text{E}[X]. \\\\\n\\end{align*} Thus we can re-write: \\begin{align*}\n\\text{E}[(X-\\mu)^2]  & = \\text{E}[ X^2 - 2X\\mu + \\mu^2] \\\\\n                        & = \\text{E}[X^2] - 2\\mu\\text{E}[X] + \\mu^2 \\\\\n                        & = \\text{E}[X^2] -2\\mu^2 + \\mu^2 \\\\\n                        & = \\text{E}[X^2] - \\mu^2 \\\\\n& = \\text{E}[X^2] - (\\text{E}[X])^2.\n\\end{align*}\n   \n\n\nQuestion 6: Functions of Random Variables\nSuppose that \\mathrm{E}[X]=\\mathrm{E}[Y]=0, \\mathrm{var}(X)=\\mathrm{var}(Y)=1, and \\mathrm{corr}(X,Y)=0.5.\n\nCompute \\mathrm{E}[3X-2Y]; and\n\\mathrm{var}(3X-2Y).\nCompute \\mathrm{E}[X^2].\n\nSolution:\n\nUsing the properties of expectations, we can re-write this as: \\begin{align*}\n\\mathrm{E}[3X-2Y] & = \\mathrm{E}[3X] + \\mathrm{E}[-2Y]\\\\\n& = 3 \\mathrm{E}[X] -2 \\mathrm{E}[Y]\\\\\n& = 3 \\times 0 -2 \\times 0\\\\\n&=0\n\\end{align*}\n\n\nUsing the properties of variances, we can re-write this as: \\begin{align*}\n\\mathrm{var}(3X-2Y) & = 3^2\\text{Var}(X) + (-2)^2\\text{Var}(Y) + 2(3)(-2)\\text{Cov}(XY)\\\\\n& =  9 \\times 1 + 4 \\times 1 -12 \\text{Corr}(XY)\\sqrt{\\text{Var}(X)\\text{Var}(Y)}\\\\\n& = 9+4 -12 \\times 0.5\\times1\\\\\n&=7\n\\end{align*}\n\n\nRecalling from Question 5 that the variance is \\mathrm{var}(X) = \\text{E}[X^2] - (\\text{E}[X])^2, we can re-arrange to obtain: \\begin{align*}\n\\mathrm{E}[X^2] & = \\mathrm{var}(X) + (\\mathrm{E}[X])^2\\\\\n& = 1+(0)^2 \\\\\n& =1\n\\end{align*}\n\n\n\nThe Sampling Distribution\nSuppose we have a random sample \\{Y_i, i=1,\\dots,N \\}, where Y_i \\stackrel{\\mathrm{i.i.d.}}{\\sim}N(\\mu,4) for i=1,\\ldots,N.\n\nWhat is the variance of the sample mean?\n\n\\displaystyle \\mathrm{Var}(\\bar{Y}) =\n\\mathrm{Var}\\left(\\frac{1}{N}\\sum_{i=1}^N Y_i\\right) =\n\\frac{N}{N^2}\\mathrm{Var}(Y) =\\frac{4}{N}.\nThis is the derivation for the variance of the sampling distribution.\n \n\nWhat is the expectation of the sample mean?\n\n\\displaystyle\\mathrm{E}[\\bar{Y}] = \\frac{N}{N}\\mathrm{E}(Y) = \\mu. This is the mean of the sampling distribution.\n\n\nWhat is the variance for another i.i.d. realization Y_{ N+1}?\n\n\\displaystyle \\mathrm{Var}(Y) = 4, because this is a sample directly from the population distribution.\n \n\nWhat is the standard error of \\bar{Y}?\n\nHere, again, we are looking at the distribution of the sample mean, so we must consider the sampling distribution, and the standard error (aka the standard distribution) is just the square root of the variance from part i.\n\\displaystyle \\mathrm{se}(\\bar{Y}) = \\sqrt{\\mathrm{Var}(\\bar{Y})} =\\frac{2}{\\sqrt{N}}.\n\n\nHypothesis Testing and Confidence Intervals\nSuppose we sample some data \\{Y_i, i=1,\\dots,n \\}, where Y_i \\stackrel{\\mathrm{i.i.d.}}{\\sim}N(\\mu,\\sigma^2) for i=1,\\ldots,n, and that you want to test the null hypothesis H_0: ~\\mu=12 vs. the alternative H_a: \\mu \\neq ` r m`, at the 0.05 significance level.\n\nWhat test statistic would you use? How do you estimate \\sigma?\nWhat is the distribution for this test statistic if the null is true?\nWhat is the distribution for the test statistic if the null is true and n \\rightarrow \\infty?\nDefine the test rejection region. (I.e., for what values of the test statistic would you reject the null?)\nHow would compute the p-value associated with a particular sample?\nWhat is the 95% confidence interval for \\mu? How should one interpret this interval?\nIf \\bar{Y} = 11, s_y = 1, and n=9, what is the test result? What is the 95% CI for \\mu?\n\n  \nThis question is asking you think about the hypothesis that the mean of your distribution is equal to 12. I give you the distribution of the data themselves (i.e., that they’re normal). To test the hypothesis, you work with the sampling distribution (i.e., the distribution of the sample mean) which is: \\bar{Y}\\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right).\n\nIf we knew \\sigma, we could use as our test statistic z=\\displaystyle \\frac{\\bar{y} - 12}{\\sigma/\\sqrt{n}}. However, here we need to estimate \\sigma so we use z=\\displaystyle \\frac{\\bar{y} - 12}{s_y/\\sqrt{n}} where \\displaystyle s_{y} = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\bar{y})^2}{n-1}}.\n\n\nIf the null is true, the z \\sim t_{n-1}(0,1). Since we estimate the mean frm the data, the degrees of freedom is n-1.\n\n\nAs n approaches infinity, t_{n-1}(0,1) \\rightarrow N(0,1).\n\n\nYou reject the null for \\{z: |z| &gt; t_{n-1,\\alpha/2}\\}.\n\n\nThe p-value is 2\\Pr(Z_{n-1} &gt;|z|). \n\n\nThe 95% CI is \\bar{Y} \\pm \\frac{s_{y}}{\\sqrt{n}} t_{n-1,\\alpha/2}.\n\nFor 19 out of 20 different samples, an interval constructed in this way will include the true value of the mean, \\mu. \n\nz = (11-12)/(1/3) = -3 and 2\\Pr(Z_{8} &gt;|z|) = .017, so we do reject the null.  The 95% CI for \\mu is 11 \\pm \\frac{1}{3}2.3 = (10.23, 11.77)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "VB_Bayes_activity1.html",
    "href": "VB_Bayes_activity1.html",
    "title": "Introduction to Bayesian Methods",
    "section": "",
    "text": "Main Materials"
  },
  {
    "objectID": "VB_Bayes_activity1.html#example-midge-wing-length",
    "href": "VB_Bayes_activity1.html#example-midge-wing-length",
    "title": "Introduction to Bayesian Methods",
    "section": "Example: Midge Wing Length",
    "text": "Example: Midge Wing Length\nWe will use this simple example to go through the steps of assessing a Bayesian model and we’ll see that MCMC can allow us to approximate the posterior distribution.\nGrogan and Wirth (1981) provide data on the wing length (in millimeters) of nine members of a species of midge (small, two-winged flies).\nFrom these measurements we wish to make inference about the population mean \\mu.\n\n# Load data\nWL.data &lt;- read.csv(\"MidgeWingLength.csv\")\nY &lt;- WL.data$WingLength\nn &lt;- length(Y)\n\nhist(Y,breaks=10,xlab=\"Wing Length (mm)\")"
  },
  {
    "objectID": "VB_Bayes_activity1.html#non-bayesian-analysis",
    "href": "VB_Bayes_activity1.html#non-bayesian-analysis",
    "title": "Introduction to Bayesian Methods",
    "section": "Non-Bayesian analysis",
    "text": "Non-Bayesian analysis\nWe might expect that these midge data could be draws from a Normal distribution \\mathcal{N}(\\mu, \\sigma^2). Recall that the MLEs for \\mu and \\sigma^2 here are simply the sample mean and sample variance respectively:\n\nm&lt;-sum(Y)/n\ns2&lt;-sum((Y-m)^2)/(n-1)\nround(c(m, s2), 3)\n\n[1] 1.804 0.017\n\n\n\nx&lt;-seq(1.4,2.2, length=50)\nhist(Y,breaks=10,xlab=\"Wing Length (mm)\", xlim=c(1.4, 2.2), freq=FALSE) \nlines(x, dnorm(x, mean=m, sd=sqrt(s2)), col=2)\n\n\n\n\n\n\n\n\nNOTE: I’ve plotted the estimate of the population distribution here, but this is not the predictive distribution (which would be a Student T because we’re estimating both the mean and variance…).\n\nThe non-Bayesian version here has the advantage of being quick and familiar. However, from our point of view it has two weaknesses:\n\nBecause we have so few data points estimates of the accuracy of our predictions aren’t available. 9 points is only barely enough to estimate a mean, so we don’t trust any of the variance calculations.\nWe can’t easily incorporate things that we might already know about midges into our analysis.\n\nLet’s see how we can do a similar analysis using a Bayesian approach, here analytically."
  },
  {
    "objectID": "VB_Bayes_activity1.html#setting-up-the-bayesian-model",
    "href": "VB_Bayes_activity1.html#setting-up-the-bayesian-model",
    "title": "Introduction to Bayesian Methods",
    "section": "Setting up the Bayesian Model",
    "text": "Setting up the Bayesian Model\nWe need to define the likelihood and the priors for our Bayesian analysis. Given the analysis that we’ve just done, let’s assume that our data come from a normal distribution with unknown mean, \\mu but that we know the variance is \\sigma^2 = 0.025. That is: \n\\mathbf{Y} \\stackrel{\\mathrm{iid}}{\\sim} \\mathcal{N}(\\mu, 0.025^2)"
  },
  {
    "objectID": "VB_Bayes_activity1.html#prior-information",
    "href": "VB_Bayes_activity1.html#prior-information",
    "title": "Introduction to Bayesian Methods",
    "section": "Prior Information",
    "text": "Prior Information\nStudies from other populations suggest that wing lengths are usually around 1.9 mm, so we set \\mu_0 = 1.9\nWe also know that lengths must be positive (\\mu &gt;0)\nWe can approximate this restriction with a normal prior distribution for \\mu as follows:\nSince most of the normal density is within two standard deviations of the mean we choose \\tau^2_0 so that\n \\mu_0 - 2\\sigma_0 &gt;0 \\Rightarrow \\sigma_0 &lt;1.9/2 = 0.95  I will choose \\sigma_0=0.8 here. Thus our prior for mu will be: \n\\mu \\sim \\mathcal{N}(1.9, 0.8^2)\n\n\nTogether, then, our full model is: \n\\begin{align*}\n\\mathbf{Y} & \\stackrel{\\mathrm{iid}}{\\sim} \\mathcal{N}(\\mu, 0.025^2)\\\\\n\\mu &\\sim \\mathcal{N}(1.9, 0.8^2)\n\\end{align*}"
  },
  {
    "objectID": "VB_Bayes_activity1.html#analytic-posterior",
    "href": "VB_Bayes_activity1.html#analytic-posterior",
    "title": "Introduction to Bayesian Methods",
    "section": "Analytic Posterior",
    "text": "Analytic Posterior\nFor this very simple case it is easy to write down the posterior distribution (up to some constant). First, note that the likelihood for the data can be written as\n\n\\begin{align*}\n\\mathcal{L} &\\propto \\prod_{i=1}^n \\frac{1}{\\sigma} \\exp\\left(-\\frac{1}{2\\sigma^2}(Y_i-\\mu)^2 \\right) \\\\\n& =  \\frac{1}{\\sigma^n} \\exp\\left(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n (Y_i-\\mu)^2 \\right)\\\\\n& \\propto \\exp\\left(-\\frac{n}{2\\sigma^2} (\\bar{Y}-\\mu)^2 \\right)\n\\end{align*}\n\nMultiplying the prior through we get the following for the posterior:\n\n\\mathrm{P}(\\mu|\\mathbf{Y}) \\propto \\exp \\left(-\\frac{n}{2\\sigma^2} (\\bar{Y}-\\mu)^2 \\right) \\exp\\left(-\\frac{1}{2\\sigma_0^2}(\\mu-\\mu_0)^2 \\right)\n\nYou can re-arrange, complete the square, etc, to get a new expression that is like\n\n\\mathrm{P}(\\mu|\\mathbf{Y}) \\propto \\exp \\left(-\\frac{1}{2\\sigma_p^2} (\\mu_p-\\mu)^2 \\right)\n\nwhere\n\n\\begin{align*}\n\\mu_p & = \\frac{n\\sigma_0^2}{\\sigma^2 + n\\sigma_0^2} \\bar{Y} +  \\frac{\\sigma^2}{\\frac{\\sigma^2}{n} + \\sigma_0^2} \\mu_0\\\\\n& \\\\\n\\sigma_p^2 & = \\left( \\frac{n}{\\sigma^2} + \\frac{1}{\\sigma_0^2} \\right)^{-1}\n\\end{align*}\n\nInstead of writing this last in terms of the variances, we could instead use precision (the inverse variance) which gives a simpler expression: \n\\tau_p = n\\tau + \\tau_0\n\nJust like in our earlier example, our estimate of the mean is a weighted average of the data and the prior, with the variance being determined by the data and prior variances.\nSo lets write a little function to calculate \\mu_p and \\tau_p and the plug in our numbers\n\ntau.post&lt;-function(tau, tau0, n){n*tau + tau0}\nmu.post&lt;-function(Ybar, mu0, sig20, sig2, n){\n  weight&lt;-sig2+n*sig20\n  \n  return(n*sig20*Ybar/weight + sig2*mu0/weight)\n}\n\nLet’s plot 3 things together – the data histogram, the prior, and the posterior\n\nmu0 &lt;- 1.9\ns20 &lt;- 0.8\ns2&lt;- 0.025 ## \"true\" variance\n\nmp&lt;-mu.post(Ybar=m, mu0=mu0, sig20=s20, sig2=s2, n=n)\ntp&lt;-tau.post(tau=1/s2, tau0=1/s20, n=n)\n\n\nx&lt;-seq(1.3,2.3, length=1000)\nhist(Y,breaks=10,xlab=\"Wing Length (mm)\", xlim=c(1.3, 2.3),\n     freq=FALSE, ylim=c(0,8)) \nlines(x, dnorm(x, mean=mu0, sd=sqrt(s20)), col=2, lty=2, lwd=2) ## prior\nlines(x, dnorm(x, mean=mp, sd=sqrt(1/tp)), col=4, lwd=2) ## posterior\nlegend(\"topleft\", legend=c(\"prior\", \"posterior\"), col=c(2,4), lty=c(2,1), lwd=2)"
  },
  {
    "objectID": "VB_Bayes_activity1.html#practice-prior-sensitivity",
    "href": "VB_Bayes_activity1.html#practice-prior-sensitivity",
    "title": "Introduction to Bayesian Methods",
    "section": "Practice: Prior sensitivity",
    "text": "Practice: Prior sensitivity\nChange the values of the mean and the variance that you choose for the prior (“hyperparameters”). What does this do to the posterior distribution. E.g., what happens if the variance you choose is small, and \\mu_0 =2.5 or so. Is this what you expect?"
  },
  {
    "objectID": "VB_Bayes_activity2.html",
    "href": "VB_Bayes_activity2.html",
    "title": "Introduction to Bayesian Methods",
    "section": "",
    "text": "Main materials"
  },
  {
    "objectID": "VB_Bayes_activity2.html#packages-and-tools",
    "href": "VB_Bayes_activity2.html#packages-and-tools",
    "title": "Introduction to Bayesian Methods",
    "section": "Packages and tools",
    "text": "Packages and tools\nFor this practical you will need to first install nimble, then be sure to install the following packages:\n\n# Load libraries\nrequire(nimble)\nrequire(HDInterval)\nlibrary(MCMCvis)\nrequire(coda) # makes diagnostic plots\nrequire(IDPmisc) # makes nice colored pairs plots to look at joint posteriors\n\n##require(mcmcplots) # another option for diagnostic plots, currently unused"
  },
  {
    "objectID": "VB_Bayes_activity2.html#example-midge-wing-length",
    "href": "VB_Bayes_activity2.html#example-midge-wing-length",
    "title": "Introduction to Bayesian Methods",
    "section": "Example: Midge Wing Length",
    "text": "Example: Midge Wing Length\nWe will use this simple example to go through the steps of assessing a Bayesian model and we’ll see that MCMC can allow us to approximate the posterior distribution.\nGrogan and Wirth (1981) provide data on the wing length (in millimeters) of nine members of a species of midge (small, two-winged flies).\nFrom these measurements we wish to make inference about the population mean \\mu.\n\n# Load data\nWL.data &lt;- read.csv(\"MidgeWingLength.csv\")\nY &lt;- WL.data$WingLength\nn &lt;- length(Y)\n\nhist(Y,breaks=10,xlab=\"Wing Length (mm)\") \n\n\n\n\n\n\n\n\nWe’ll also need summary statistics for the data that we calculated last time:\n\nm&lt;-sum(Y)/n\ns2&lt;-sum((Y-m)^2)/(n-1)"
  },
  {
    "objectID": "VB_Bayes_activity2.html#recall-setting-up-the-bayesian-model",
    "href": "VB_Bayes_activity2.html#recall-setting-up-the-bayesian-model",
    "title": "Introduction to Bayesian Methods",
    "section": "Recall: Setting up the Bayesian Model",
    "text": "Recall: Setting up the Bayesian Model\nWe need to define the likelihood and the priors for our Bayesian analysis. Given the analysis that we’ve just done, let’s assume that our data come from a normal distribution with unknown mean, \\mu but that we know the variance is \\sigma^2 = 0.025. That is: \n\\mathbf{Y} \\stackrel{\\mathrm{iid}}{\\sim} \\mathcal{N}(\\mu, 0.025^2)\n\nIn the last activity we our prior for \\mu to be be: \n\\mu \\sim \\mathcal{N}(1.9, 0.8^2)\n Together, then, our full model is: \n\\begin{align*}\n\\mathbf{Y} & \\stackrel{\\mathrm{iid}}{\\sim} \\mathcal{N}(\\mu, 0.025^2)\\\\\n\\mu &\\sim \\mathcal{N}(1.9, 0.8^2)\n\\end{align*}\n\nIn the previous activity we wrote a function to calculate \\mu_p and \\tau_p and then plugged in our numbers:\n\ntau.post&lt;-function(tau, tau0, n){n*tau + tau0}\nmu.post&lt;-function(Ybar, mu0, sig20, sig2, n){\n  weight&lt;-sig2+n*sig20\n  \n  return(n*sig20*Ybar/weight + sig2*mu0/weight)\n}\n\nFinally we plotted 3 things together – the data histogram, the prior, and the posterior\n\nmu0 &lt;- 1.9\ns20 &lt;- 0.8\ns2&lt;- 0.025 ## \"true\" variance\n\nmp&lt;-mu.post(Ybar=m, mu0=mu0, sig20=s20, sig2=s2, n=n)\ntp&lt;-tau.post(tau=1/s2, tau0=1/s20, n=n)\n\n\nx&lt;-seq(1.3,2.3, length=1000)\nhist(Y,breaks=10,xlab=\"Wing Length (mm)\", xlim=c(1.3, 2.3),\n     freq=FALSE, ylim=c(0,8)) \nlines(x, dnorm(x, mean=mu0, sd=sqrt(s20)), col=2, lty=2, lwd=2) ## prior\nlines(x, dnorm(x, mean=mp, sd=sqrt(1/tp)), col=4, lwd=2) ## posterior\nlegend(\"topleft\", legend=c(\"prior\", \"posterior\"), col=c(2,4), lty=c(2,1), lwd=2)"
  },
  {
    "objectID": "VB_Bayes_activity2.html#specifying-the-model",
    "href": "VB_Bayes_activity2.html#specifying-the-model",
    "title": "Introduction to Bayesian Methods",
    "section": "Specifying the model",
    "text": "Specifying the model\nFirst we must encode our choices for our data model and priors to pass them to the fitting routines in nimble. This involves setting up a {\\tt model} that includes the likelihood for each data point and a prior for every parameter we want to estimate. Here is an example of how we would do this for the simple model we fit for the midge data (note that nimble uses the precision instead of the variance or sd for the normal distribution):\n\nmodelCode &lt;-  nimbleCode({\n\n  ## Likelihood\n  for(i in 1:n){\n    Y[i] ~ dnorm(mu,tau)\n  }\n\n  ## Prior for mu\n  mu  ~ dnorm(mu0,tau0)\n\n} ## close model\n)\n\nThis model is formally in the BUGS language (also used by JAGS, WinBugs, etc). Now we will create the nimble model\n\nmodel1 &lt;- nimbleModel(code = modelCode, name = \"model1\", \n                    constants = list(tau=1/s2, mu0=mu0,\n                                    tau0=1/s20, n=n),\n                    data  = list(Y=Y), \n                    inits = list(mu=5))\n\nDefining model\n\n\nBuilding model\n\n\nSetting data and initial values\n\n\nRunning calculate on model\n  [Note] Any error reports that follow may simply reflect missing values in model variables.\n\n\nChecking model sizes and dimensions\n\nmodel1$getNodeNames()\n\n [1] \"mu\"   \"Y[1]\" \"Y[2]\" \"Y[3]\" \"Y[4]\" \"Y[5]\" \"Y[6]\" \"Y[7]\" \"Y[8]\" \"Y[9]\"\n\n## just checking it can compile\nCmodel1&lt;- compileNimble(model1)\n\nCompiling\n  [Note] This may take a minute.\n  [Note] Use 'showCompilerOutput = TRUE' to see C++ compilation details.\n\n\nThen we run the MCMC and, see how the output looks for a short chain:\n\nmcmc.out &lt;- nimbleMCMC(code = modelCode, \n                       constants = list(tau=1/s2, mu0=mu0,\n                                    tau0=1/s20,n=n),\n                       data  = list(Y=Y),\n                       inits = list(mu=5),\n                       nchains = 1, niter = 100,\n                       #summary = TRUE, WAIC = TRUE,\n                       monitors = c('mu'))\n\nDefining model\n\n\nBuilding model\n\n\nSetting data and initial values\n\n\nRunning calculate on model\n  [Note] Any error reports that follow may simply reflect missing values in model variables.\n\n\nChecking model sizes and dimensions\n\n\nChecking model calculations\n\n\nCompiling\n  [Note] This may take a minute.\n  [Note] Use 'showCompilerOutput = TRUE' to see C++ compilation details.\n\n\nrunning chain 1...\n\n\n|-------------|-------------|-------------|-------------|\n|-------------------------------------------------------|\n\ndim(mcmc.out)\n\n[1] 100   1\n\nhead(mcmc.out)\n\n           mu\n[1,] 1.865939\n[2,] 1.898771\n[3,] 1.774245\n[4,] 1.855380\n[5,] 1.762429\n[6,] 1.790950\n\n\n\nsamps&lt;-as.mcmc(mcmc.out)\nplot(samps)\n\n\n\n\n\n\n\n\nMCMC is a rejection algorithm that often needs to converge or “burn-in” – that is we need to potentially move until we’re taking draws from the correct distribution. Unlike for optimization problems, this does not mean that the algorithm heads toward a single value. Instead we’re looking for a pattern where the draws are seemingly unrelated and random. To assess convergence we look at trace plots, the goal is to get traces that look like “fuzzy caterpillars”.\nSometimes at the beginning of a run, if we start far from the area near the posterior mean of the parameter, we will instead get something that looks like a trending time series. If this is the case we have to drop the samples that were taken during the burn-in phase. Here’s an example of how to do that, also now running 2 chains simultaneously.\n\nmcmc.out &lt;- nimbleMCMC(code = modelCode, \n                       constants = list(tau=1/s2, mu0=mu0,\n                                    tau0=1/s20,n=n),\n                       data  = list(Y=Y),\n                       inits = list(mu=5),\n                       nchains = 2, niter = 11000,\n                       nburnin = 1000,\n                       #summary = TRUE, WAIC = TRUE,\n                       monitors = c('mu'))\n\nDefining model\n\n\nBuilding model\n\n\nSetting data and initial values\n\n\nRunning calculate on model\n  [Note] Any error reports that follow may simply reflect missing values in model variables.\n\n\nChecking model sizes and dimensions\n\n\nChecking model calculations\n\n\nCompiling\n  [Note] This may take a minute.\n  [Note] Use 'showCompilerOutput = TRUE' to see C++ compilation details.\n\n\nrunning chain 1...\n\n\n|-------------|-------------|-------------|-------------|\n|-------------------------------------------------------|\n\n\nrunning chain 2...\n\n\n|-------------|-------------|-------------|-------------|\n|-------------------------------------------------------|\n\ndim(mcmc.out$chain1)\n\n[1] 10000     1\n\nhead(mcmc.out$chain1)\n\n           mu\n[1,] 1.784885\n[2,] 1.772599\n[3,] 1.786826\n[4,] 1.862633\n[5,] 1.779696\n[6,] 1.823475\n\n\n\nsamp&lt;-as.mcmc(mcmc.out$chain1)\nplot(samp)\n\n\n\n\n\n\n\n\nThis is a very fuzzy caterpillar!\nWe also often want to check the autocorrelation in the chain.\n\nacfplot(samp, lag=20, aspect=\"fill\", ylim=c(-1,1))\n\n\n\n\n\n\n\n\nThis is really good! It means that the samples are almost entirely uncorrelated.\nFinally we can also use the summary function to examine the samples generated:\n\nsummary(samp)\n\n\nIterations = 1:10000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean             SD       Naive SE Time-series SE \n      1.805159       0.052199       0.000522       0.000522 \n\n2. Quantiles for each variable:\n\n 2.5%   25%   50%   75% 97.5% \n1.704 1.770 1.805 1.841 1.907 \n\n\nLet’s compare these draws to what we got with our analytic solution:\n\nx&lt;-seq(1.3,2.3, length=1000)\nhist(samp, xlab=\"mu\", xlim=c(1.3, 2.3),\n     freq=FALSE, ylim=c(0,8), main =\"posterior samples\") \nlines(x, dnorm(x, mean=mu0, sd=sqrt(s20)), col=2, lty=2, lwd=2) ## prior\nlines(x, dnorm(x, mean=mp, sd=sqrt(1/tp)), col=4, lwd=2) ## posterior\nlegend(\"topleft\", legend=c(\"prior\", \"analytic posterior\"), col=c(2,4), lty=c(2,1), lwd=2)\n\n\n\n\n\n\n\n\nIt worked!\nAs with the analytic approach, it’s always a good idea when you run your analyses to see how sensitive is your result to the priors you choose. Unless you are purposefully choosing an informative prior, we usually want the prior and posterior to look different, as we see here. You can experiment yourself and try changing the prior to see how this effects the posterior."
  },
  {
    "objectID": "VB_Bayes_activity2.html#practice-applying-to-a-new-dataset",
    "href": "VB_Bayes_activity2.html#practice-applying-to-a-new-dataset",
    "title": "Introduction to Bayesian Methods",
    "section": "Practice: Applying to a new dataset",
    "text": "Practice: Applying to a new dataset\nDownload VecTraits dataset 562 (Kutcherov et al. 2018. Effects of temperature and photoperiod on the immature development in Cassida rubiginosa Mull. and C. stigmatica Sffr. (Coleoptera: Chrysomelidae). Sci. Rep. 9: 10047). This dataset explores the effects of temperature and photoperiod on body size (weight in mg) for Cassida stigmatica, a type of small beetle. Subset the data so you focus on one temperature/photoperiod combination (you could also choose to subset by sex). Using the same model as above, potentially with a different prior distribution, and with the value of \\tau set to 1/s^2 (where s is the empirical standard deviation of your dataset), redo the analysis above."
  },
  {
    "objectID": "VB_Bayes_activity2.html#practice-updating-the-model",
    "href": "VB_Bayes_activity2.html#practice-updating-the-model",
    "title": "Introduction to Bayesian Methods",
    "section": "Practice: Updating the model",
    "text": "Practice: Updating the model\nRedo the previous analysis placing a gamma prior on \\mu as well. Set the prior so that the mean and variance are the same as in the normal example from above (use moment matching). Do you get something similar?"
  },
  {
    "objectID": "materials.html",
    "href": "materials.html",
    "title": "EEID 2024 Workshop Training Materials",
    "section": "",
    "text": "Many of the materials here were initially developed as part of the VectorByte Initiative and the older VectorBiTE RCN. As such, they have been developed with the effort of many people over the years. Most of those for this workshop originally developed by Dr. Leah R. Johnson and Sean Sorek. They have been modified for this workshop by Leah Johnson and Victor Pena"
  },
  {
    "objectID": "materials.html#hardware-and-software",
    "href": "materials.html#hardware-and-software",
    "title": "EEID 2024 Workshop Training Materials",
    "section": "Hardware and Software",
    "text": "Hardware and Software\nWe will be using R for all data manipulation and analyses/model fitting. Any operating system (Windows, Mac, Linux) will do, as long as you have R (version 4.2 or higher) installed.\nYou may use any IDE/ GUI for R (VScode, RStudio, Emacs, etc). For most people, RStudio is a good option. Whichever one you decide to use, please make sure it is installed and test it before the workshop."
  },
  {
    "objectID": "materials.html#pre-requisites",
    "href": "materials.html#pre-requisites",
    "title": "EEID 2024 Workshop Training Materials",
    "section": "Pre-requisites",
    "text": "Pre-requisites\nWe are assuming familiarity with R basics as well as at least introductory statistics, including up through linear models and the idea of a likelihood. If you would like materials to review, we recommend that you do the following:\n\nGo to The Multilingual Quantitative Biologist, and read+work through the Biological Computing in R Chapter.\nIn addition / alternatively to pre-work element (1), here are some resources for brushing up on R at the end of the Intro R Chapter you can try. But there are many more resources online (e.g., this and this ) – pick something that suits your learning style.\nReview background on introductory probability and statistics (solutions to exercises). You can also use the resources on The Multilingual Quantitative Biologist - Basic Data Analyses and Statistics"
  },
  {
    "objectID": "materials.html#introduction-to-traits",
    "href": "materials.html#introduction-to-traits",
    "title": "EEID 2024 Workshop Training Materials",
    "section": "Introduction to traits",
    "text": "Introduction to traits\n\nLecture slides\nCator et al. 2020. The Role of Vector Trait Variation in Vector-Borne Disease Dynamics"
  },
  {
    "objectID": "materials.html#intro-to-bayes",
    "href": "materials.html#intro-to-bayes",
    "title": "EEID 2024 Workshop Training Materials",
    "section": "Intro to Bayes",
    "text": "Intro to Bayes\n\nLecture Slides, Practical 1\nDatasets:\n\nMidge data"
  },
  {
    "objectID": "materials.html#bayesian-computation-and-mcmc",
    "href": "materials.html#bayesian-computation-and-mcmc",
    "title": "EEID 2024 Workshop Training Materials",
    "section": "Bayesian computation and MCMC",
    "text": "Bayesian computation and MCMC\n\nLecture Slides, Practical 2A"
  },
  {
    "objectID": "materials.html#fitting-tpcs-using-bayestpc",
    "href": "materials.html#fitting-tpcs-using-bayestpc",
    "title": "EEID 2024 Workshop Training Materials",
    "section": "Fitting TPCs using bayesTPC",
    "text": "Fitting TPCs using bayesTPC\n\nPractical"
  },
  {
    "objectID": "Stats_review.html",
    "href": "Stats_review.html",
    "title": "VectorByte Methods Training 2023",
    "section": "",
    "text": "Main materials\nSolutions to exercises"
  },
  {
    "objectID": "Stats_review.html#some-probability-notation",
    "href": "Stats_review.html#some-probability-notation",
    "title": "VectorByte Methods Training 2023",
    "section": "Some probability notation",
    "text": "Some probability notation\nWe have a set, S of all possible events. Let \\text{Pr}(A) (or alternatively \\text{Prob}(A)) be the probability of event A. Then:\n\nA^c is the complement to A (all events that are not A).\nA \\cup B is the union of events A and B (“A or B”).\nA \\cap B is the intersection of events A and B (“A and B”).\n\\text{Pr}(A|B) is the conditional probability of A given that B occurs."
  },
  {
    "objectID": "Stats_review.html#axioms-of-probability",
    "href": "Stats_review.html#axioms-of-probability",
    "title": "VectorByte Methods Training 2023",
    "section": "Axioms of Probability",
    "text": "Axioms of Probability\nThese are the basic definitions that we use when we talk about probabilities. You’ve probably seen these before, but maybe not in mathematical notation. If the notation is new to you, I suggest that you use the notation above to translate these statements into words and confirm that you understand what they mean. I give you an example for the first statement.\n\n\\sum_{i \\in S} \\text{Pr}(A_i)=1, where 0 \\leq \\text{Pr}(A_i) \\leq 1 (the probabilities of all the events that can happen must sum to one, and all of the individual probabilities must be less than one)\n\\text{Pr}(A)=1-\\text{Pr}(A^c)\n\\text{Pr}(A \\cup B) = \\text{Pr}(A) + \\text{Pr}(B) -\\text{Pr}(A \\cap B)\n\\text{Pr}(A \\cap B) = \\text{Pr}(A|B)\\text{Pr}(B)\nIf A and B are independent, then \\text{Pr}(A|B) = \\text{Pr}(A)"
  },
  {
    "objectID": "Stats_review.html#bayes-theorem",
    "href": "Stats_review.html#bayes-theorem",
    "title": "VectorByte Methods Training 2023",
    "section": "Bayes Theorem",
    "text": "Bayes Theorem\nBayes Theorem allows us to related the conditional probabilities of two events A and B:\n\\begin{align*}\n\\text{Pr}(A|B) & = \\frac{\\text{Pr}(B|A)\\text{Pr}(A)}{\\text{Pr}(B)}\\\\\n&\\\\\n& =  \\frac{\\text{Pr}(B|A)\\text{Pr}(A)}{\\text{Pr}(B|A)\\text{Pr}(A) + \\text{Pr}(B|A^c)\\text{Pr}(A^c)}\n\\end{align*}"
  },
  {
    "objectID": "Stats_review.html#discrete-rvs-and-their-probability-distributions",
    "href": "Stats_review.html#discrete-rvs-and-their-probability-distributions",
    "title": "VectorByte Methods Training 2023",
    "section": "Discrete RVs and their Probability Distributions",
    "text": "Discrete RVs and their Probability Distributions\nMany things that we observe are naturally discrete. For instance, whole numbers of chairs or win/loss outcomes for games. Discrete probability distributions are used to describe these kinds of events.\nFor discrete RVs, the distribution of probabilities is described by the probability mass function (pmf), f_k such that:\n\\begin{align*}\nf_k  \\equiv \\text{Pr}(X & = k) \\\\\n\\text{where } 0\\leq f_k \\leq 1 & \\text{ and } \\sum_k f_k = 1\n\\end{align*}\nFor example, for a fair 6-sided die:\nf_k = 1/6 for k= \\{1,2,3,4,5,6\\}.\n\\star Question 1: For the six-sided fair die, what is f_k if k=7? k=1.5?\nRelated to the pmf is the cumulative distribution function (cdf), F(x). F(x) \\equiv \\text{Pr}(X \\leq x)\nFor the 6-sided die F(x)= \\displaystyle\\sum_{k=1}^{x} f_k\nwhere x \\in 1\\dots 6.\n\\star Question 2: For the fair 6-sided die, what is F(3)? F(7)? F(1.5)?\n\nVisualizing distributions of discrete RVs in R\nExample: Imagine a RV can take values 1 through 10, each with probability 0.1:\n \n\nvals&lt;-seq(1,10, by=1)\npmf&lt;-rep(0.1, 10)\ncdf&lt;-pmf[1]\nfor(i in 2:10) cdf&lt;-c(cdf, cdf[i-1]+pmf[i])\npar(mfrow=c(1,2), bty=\"n\")\nbarplot(height=pmf, names.arg=vals, ylim=c(0, 1), main=\"pmf\", col=\"blue\")\nbarplot(height=cdf, names.arg=vals, ylim=c(0, 1), main=\"cdf\", col=\"red\")"
  },
  {
    "objectID": "Stats_review.html#continuous-rvs-and-their-probability-distributions",
    "href": "Stats_review.html#continuous-rvs-and-their-probability-distributions",
    "title": "VectorByte Methods Training 2023",
    "section": "Continuous RVs and their Probability Distributions",
    "text": "Continuous RVs and their Probability Distributions\nThings are just a little different for continuous RVs. Instead we use the probability density function (pdf) of the RV, and denote it by f(x). It still describes how relatively likely are alternative values of an RV – that is, if the pdf his higher around one value than around another, then the first is more likely to happen. However, the pdf does not return a probability, it is a function that describes the probability density.\nAn analogy:\nProbabilities are like weights of objects. The PMF tells you how much weight each possible value or outcome contributes to a whole. The PDF tells you how dense it is around a value. To calculate the weight of a real object, you need to also know the size of the area that you’re interested in and the density there The probability that your RV takes exactly any value is zero, just like the probability that any atom in a very thin wire is lined up at exactly that position is zero (and to the amount of mass at that location is zero). However, you can take a very thin slice around that location to see how much material is there.\nRelated to the pdf is the cumulative distribution function (cdf), F(x). \nF(x) \\equiv \\text{Pr}(X \\leq x)\n For a continuous distribution: \nF(x)= \\int_{-\\infty}^x f(x')dx'\n\n \n For a normal distribution with mean 0, what is F(0)?\n \n\nVisualizing distributions of continuous RVs in R\nExample: exponential RV, where f(x) = re^{-rx}:\n\n\nvals&lt;-seq(0,10, length=1000)\nr&lt;-0.5\npar(mfrow=c(1,2), bty=\"n\")\nplot(vals, dexp(vals, rate=r), main=\"pdf\", col=\"blue\", type=\"l\", lwd=3, ylab=\"\", xlab=\"\")\nplot(vals, pexp(vals, rate=r), main=\"cdf\", ylim=c(0,1), col=\"red\",\n     type=\"l\", lwd=3, ylab=\"\", xlab=\"\")"
  },
  {
    "objectID": "Stats_review.html#confidence-intervals",
    "href": "Stats_review.html#confidence-intervals",
    "title": "VectorByte Methods Training 2023",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\nSuppose Z_{n-p} \\sim t_{n-p}(0,1). A centered interval is on this t distribution can be written as: \\text{Pr}(-t_{n-p,\\alpha/2} \\&lt; Z\\_{n-p} \\&lt; t_{n-p,\\alpha/2}) = 1-\\alpha. That is, between these values of the t distribution (1-\\alpha)\\times 100 percent of the probability is contained in that symmetric interval. We can visually indicate these location on a plot of the t distribution (here with df=5 and \\alpha=0.05):\n\nx&lt;-seq(-4.5, 4.5, length=1000)\nalpha=0.05\n\n## draw a line showing the normal pdf on the histogram\nplot(x, dt(x, df=5), col=\"black\", lwd=2, type=\"l\", xlab=\"x\", ylab=\"\")\nabline(v=qt(alpha/2, df=5), col=3, lty=2, lwd=2)\nabline(v=qt(1-alpha/2, df=5), col=2, lty=2, lwd=2)\n\nlegend(\"topright\", \n       legend=c(\"t, df=5\", \"lower a/2\", \"upper a/2\"),\n       col=c(1,3,2), lwd=2, lty=c(1, 2,2))\n\n\n\n\n\n\n\n\nIn the R code here, {\\tt qt} is the Student-t “quantile function”. The function {\\tt qt(alpha, df)} returns a value z such that \\alpha = P(Z_{\\mathrm{df}} &lt; z), i.e., t_{\\mathrm{df},\\alpha}.\nHow can we use this to determine the confidence interval for \\theta? Since \\theta \\sim t_{n-p}(\\mu, s^2), we can replace the Z_{n-p} in the interval above with the definition in terms of \\theta, \\mu and s and rearrange: \\begin{align*}\n1-\\alpha& = \\text{Pr}\\left(-t_{n-p,\\alpha/2} &lt; \\frac{\\mu - \\bar{\\theta}}{s} &lt;\nt_{n-p,\\alpha/2}\\right) \\\\\n&=\n\\text{Pr}(\\bar{\\theta}-t_{n-p,\\alpha/2}s &lt; \\mu &lt;\n\\bar{\\theta} + t_{n-p,\\alpha/2}s)\n\\end{align*}\nThus (1-\\alpha)*100% of the time, \\mu is within the confidence interval (written in two equivalent ways):\n\\bar{\\theta} \\pm t_{n-p,\\alpha/2} \\times s \\;\\;\\; \\Leftrightarrow \\;\\;\\; \\bar{\\theta}-t_{n-p,\\alpha/2} \\times s, \\bar{\\theta} + t_{n-p,\\alpha/2}\\times s\nWhy should we care about confidence intervals?\n\nThe confidence interval captures the amount of information in the data about the parameter.\nThe center of the interval tells you what your estimate is.\nThe length of the interval tells you how sure you are about your estimate."
  },
  {
    "objectID": "Stats_review.html#p-values",
    "href": "Stats_review.html#p-values",
    "title": "VectorByte Methods Training 2023",
    "section": "p-Values",
    "text": "p-Values\nWhat is a p-value? The American Statistical Association issued a statement where they defined it in the following way:\n“Informally, a p-value is the probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value.” (ASA Statement on Statistical Significance and P-Values.)\nMore formally, we formulate a p-value in terms of a null hypothesis/model and test whether or not our observed data are more extreme than we would expect under that specific null model. In your previous courses you’ve probably seen very specific null models, corresponding to, for instance the null hypothesis that the mean of your data is normally distributed with mean m (often m=0). We often denote the null model as H_0 and the alternative as H_a or H_1. For instance, for our example above with \\theta we might want to test the following:\nH_0: \\bar{\\theta}=0 \\;\\;\\; \\text{vs.} \\;\\;\\; H_a: \\bar{\\theta}\\neq 0\nTo perform the hypothesis test we would FIRST choose our rejection level, \\alpha. Although convention is to use \\alpha =0.05 corresponding to a 95% confidence region, one could choose based on how sure one needs to be for a particular application. Next we build our test statistic. There are two cases, first if we know \\sigma and second if we don’t.\nIf we knew the variance \\sigma^2, our test statistic would be Z=\\frac{\\bar{\\theta}-0}{\\sigma}, and we expect that this should have a standard normal distribution, i.e., Z\\sim\\mathcal{N}(0,1). If we don’t know \\sigma and instead estimate is as s (which is most of the time), our test statistic would be Z_{df}=\\frac{\\bar{\\theta}-0}{s} (i.e., it would have a t-distribution).\nWe calculate the value of the appropriate statistic (either Z or Z_{df}) for our data, and then we compare it to the values of the standard distribution (normal or t, respectively) corresponding to the \\alpha level that we chose, i.e., we see if the number that we got for our statistic is inside the horizontal lines that we drew on the standard distribution above. If it is, then the data are consistent with the null hypothesis and we cannot reject the null. If the statistic is outside the region the data are NOT consistent with the null, and instead we reject the null and use the alternative as our new working hypothesis.\nNotice that this process is focused on the null hypothesis. We cannot tell if the alternative hypothesis is true, or, really, if it’s actually better than the null. We can only say that the null is not consistent with our data (i.e., we can falsify the null) at a given level of certainty.\nAlso, the hypothesis testing process is the same as building a confidence interval, as above, and then seeing if the null hypothesis is within your confidence interval. If the null is outside of your confidence interval then you can reject your null at the level of certainty corresponding to the \\alpha that you used to build your CI. If the value for the null is within your CI, you cannot reject at that level."
  },
  {
    "objectID": "Stats_review.html#the-sampling-distribution-1",
    "href": "Stats_review.html#the-sampling-distribution-1",
    "title": "VectorByte Methods Training 2023",
    "section": "The Sampling Distribution",
    "text": "The Sampling Distribution\nSuppose we have a random sample \\{Y_i, i=1,\\dots,N \\}, where Y_i \\stackrel{\\mathrm{i.i.d.}}{\\sim}N(\\mu,9) for i=1,\\ldots,N.\n\nWhat is the variance of the sample mean?\nWhat is the expectation of the sample mean?\nWhat is the variance for another i.i.d. realization Y_{ N+1}?\nWhat is the standard error of \\bar{Y}?"
  },
  {
    "objectID": "Stats_review.html#hypothesis-testing-and-confidence-intervals",
    "href": "Stats_review.html#hypothesis-testing-and-confidence-intervals",
    "title": "VectorByte Methods Training 2023",
    "section": "Hypothesis Testing and Confidence Intervals",
    "text": "Hypothesis Testing and Confidence Intervals\nSuppose we sample some data \\{Y_i, i=1,\\dots,n \\}, where Y_i \\stackrel{\\mathrm{i.i.d.}}{\\sim}N(\\mu,\\sigma^2) for i=1,\\ldots,n, and that you want to test the null hypothesis H_0: ~\\mu=12 vs. the alternative H_a: \\mu \\neq 12, at the 0.05 significance level.\n\nWhat test statistic would you use? How do you estimate \\sigma?\nWhat is the distribution for this test statistic if the null is true?\nWhat is the distribution for the test statistic if the null is true and n \\rightarrow \\infty?\nDefine the test rejection region. (I.e., for what values of the test statistic would you reject the null?)\nHow would compute the p-value associated with a particular sample?\nWhat is the 95% confidence interval for \\mu? How should one interpret this interval?\nIf \\bar{Y} = 11, s_y = 1, and n=9, what is the test result? What is the 95% CI for \\mu?"
  },
  {
    "objectID": "VB_Bayes1.html#learning-objectives",
    "href": "VB_Bayes1.html#learning-objectives",
    "title": "VectorByte Methods Training",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUnderstand the basic principles underlying Bayesian modeling methodology\nIntroduce how to use Bayesian inference for real-world problems\nIntroduce computation tools to perform inference for simple models in R (how to turn the Bayesian crank)"
  },
  {
    "objectID": "VB_Bayes1.html#what-is-bayesian-inference",
    "href": "VB_Bayes1.html#what-is-bayesian-inference",
    "title": "VectorByte Methods Training",
    "section": "What is Bayesian Inference?",
    "text": "What is Bayesian Inference?\nIn the Bayesian approach our probabilities numerically represent rational beliefs.\n\nBayes rule provides a rational method for updating those beliefs in light of new information and incorporating/quantifying uncertainty in those beliefs.\n\nThus, Bayesian inference is an approach for understanding data inductively."
  },
  {
    "objectID": "VB_Bayes1.html#recall-bayes-theorem",
    "href": "VB_Bayes1.html#recall-bayes-theorem",
    "title": "VectorByte Methods Training",
    "section": "Recall: Bayes Theorem",
    "text": "Recall: Bayes Theorem\nBayes Theorem allows us to relate the conditional probabilities of two events \\(A\\) and \\(B\\): \\[\n\\text{Pr}(A|B) = \\frac{\\text{Pr}(B|A)\\text{Pr}(A)}{\\text{Pr}(B)}\n\\]"
  },
  {
    "objectID": "VB_Bayes1.html#what-is-bayesian-inference-1",
    "href": "VB_Bayes1.html#what-is-bayesian-inference-1",
    "title": "VectorByte Methods Training",
    "section": "What is Bayesian Inference?",
    "text": "What is Bayesian Inference?\nWe can re-write Bayes rule in terms of our parameters, \\(\\theta\\) and our data, \\(Y\\): \\[\\begin{align*}\n\\text{Pr}(\\theta|Y) & = \\frac{\\text{Pr}(Y|\\theta)\\text{Pr}(\\theta)}{\\text{Pr}(Y)}\n\\end{align*}\\]\nThe LHS is the main quantity of interest in a Bayesian analysis, the posterior, denoted \\(f(\\theta|Y)\\): \\[\n\\overbrace{f(\\theta|Y)}^\\text{Posterior} \\propto \\overbrace{\\mathcal{L}(\\theta; Y)}^\\text{Likelihood} \\times \\overbrace{f(\\theta)}^\\text{Prior}\n\\]"
  },
  {
    "objectID": "VB_Bayes1.html#bayesian-methods-provide",
    "href": "VB_Bayes1.html#bayesian-methods-provide",
    "title": "VectorByte Methods Training",
    "section": "Bayesian methods provide",
    "text": "Bayesian methods provide\n\nmodels for rational, quantitative learning\nparameter estimates with good statistical properties\nestimators that work for small and large sample sizes\nparsimonious descriptions of data, predictions for missing data, and forecasts for future data\na coherent computational framework for model estimation, selection and validation"
  },
  {
    "objectID": "VB_Bayes1.html#classical-vs-bayesian",
    "href": "VB_Bayes1.html#classical-vs-bayesian",
    "title": "VectorByte Methods Training",
    "section": "Classical vs Bayesian",
    "text": "Classical vs Bayesian\nThe fundamental differences between classical and Bayesian methods is what is fixed and what is random in an analysis.\n\n\n\n\nParadigm\nFixed\nRandom\n\n\n\n\nClassical\nparam (\\(\\theta\\))\ndata (\\(Y\\))\n\n\nBayesian\ndata (\\(Y\\))\nparam (\\(\\theta\\))"
  },
  {
    "objectID": "VB_Bayes1.html#whywhy-not-bayesian-statistics",
    "href": "VB_Bayes1.html#whywhy-not-bayesian-statistics",
    "title": "VectorByte Methods Training",
    "section": "Why/Why Not Bayesian Statistics?",
    "text": "Why/Why Not Bayesian Statistics?\n\nPros\n\nIf \\(f(\\theta)\\) & \\(\\mathcal{L}(\\theta; Y)\\) represent a rational person’s beliefs, then Bayes’ rule is an optimal method of updating these beliefs given new info (Cox 1946, 1961; Savage 1954; 1972).\nProvides more intuitive answers in terms of the probability that parameters have particular values.\nIn many complicated statistical problems there are no obvious non-Bayesian inference methods."
  },
  {
    "objectID": "VB_Bayes1.html#whywhy-not-bayesian-statistics-1",
    "href": "VB_Bayes1.html#whywhy-not-bayesian-statistics-1",
    "title": "VectorByte Methods Training",
    "section": "Why/Why Not Bayesian Statistics?",
    "text": "Why/Why Not Bayesian Statistics?\n\nCons\n\nIt can be hard to mathematically formulate prior beliefs (choice of \\(f(\\theta)\\) often ad hoc or for computational reasons).\nPosterior distributions can be sensitive to prior choice.\nAnalyses can be computationally costly."
  },
  {
    "objectID": "VB_Bayes1.html#steps-to-making-inference",
    "href": "VB_Bayes1.html#steps-to-making-inference",
    "title": "VectorByte Methods Training",
    "section": "Steps to Making Inference",
    "text": "Steps to Making Inference\n\nResearch question\nData collection\nModel \\(Y_i \\approx f(X_i)\\)\nEstimate the parameter in the model with uncertainty\nMake inference\n\nThe difference between Classical and Bayesian lies in step 4:\n\nClassical uses maximum likelihood estimatation\n\nBayesian derives a posterior distribution."
  },
  {
    "objectID": "VB_Bayes1.html#example-estimating-the-probability-of-a-rare-event",
    "href": "VB_Bayes1.html#example-estimating-the-probability-of-a-rare-event",
    "title": "VectorByte Methods Training",
    "section": "Example: Estimating the probability of a rare event",
    "text": "Example: Estimating the probability of a rare event\nSuppose we are interested in the prevalence of an infectious disease in a small city. A small random sample of 20 individuals will be checked for infection.\n\nInterest is in the fraction of infected individuals \\[\n\\theta \\in \\Theta =[0,1]\n\\]\nThe data records the number of infected individuals \\[\ny \\in \\mathcal{Y} =\\{0,1, \\ldots, 20\\}\n\\]"
  },
  {
    "objectID": "VB_Bayes1.html#example-likelihoodsampling-model",
    "href": "VB_Bayes1.html#example-likelihoodsampling-model",
    "title": "VectorByte Methods Training",
    "section": "Example: Likelihood/sampling model",
    "text": "Example: Likelihood/sampling model\nBefore the sample is obtained, the number of infected individuals is unknown.\n\nLet \\(Y\\) denote this to-be-determined value\nIf \\(\\theta\\) were known, a sensible sampling model is \\[\nY|\\theta \\sim  \\mathrm{Bin} (20, \\theta)\n\\]"
  },
  {
    "objectID": "VB_Bayes1.html#example-prior",
    "href": "VB_Bayes1.html#example-prior",
    "title": "VectorByte Methods Training",
    "section": "Example: Prior",
    "text": "Example: Prior\nOther studies from various parts of the country indicate that the infection rate ranges from about 0.05 to 0.20, with an average prevalence of 0.1.\n\nMoment matching from a beta distribution (a convenient choice) gives the prior \\(\\theta \\sim \\mathrm{Beta} (2,20)\\)"
  },
  {
    "objectID": "VB_Bayes1.html#example-posterior",
    "href": "VB_Bayes1.html#example-posterior",
    "title": "VectorByte Methods Training",
    "section": "Example: Posterior",
    "text": "Example: Posterior\nThe prior and sample model combination: \\[\\begin{align*}\n\\theta & \\sim  \\mathrm{Beta} (a,b) \\\\\nY|\\theta &  \\sim  \\mathrm{Bin} (n, \\theta)\n\\end{align*}\\] and an observed \\(y\\) (the data), leads to the posterior \\[\np(\\theta|y)= \\mathrm{Beta}(a+y, b+n-y)\n\\]"
  },
  {
    "objectID": "VB_Bayes1.html#example-posterior-1",
    "href": "VB_Bayes1.html#example-posterior-1",
    "title": "VectorByte Methods Training",
    "section": "Example: Posterior",
    "text": "Example: Posterior\nFor our case, we have \\(a=2\\), \\(b=20\\), \\(n=20\\).\nIf we don’t find any infections (\\(y=0\\)) our posterior is: \\[\np(\\theta |y=0)= \\mathrm{Beta}(2, 40)\n\\]"
  },
  {
    "objectID": "VB_Bayes1.html#example-sensitivity-analysis",
    "href": "VB_Bayes1.html#example-sensitivity-analysis",
    "title": "VectorByte Methods Training",
    "section": "Example: Sensitivity Analysis",
    "text": "Example: Sensitivity Analysis\nHow influential is our prior? The posterior expectation is \\[\n\\mathrm{E}\\{\\theta|Y=y\\} =   \\frac{n}{w+n} \\bar{y} + \\frac{w}{w+n} \\theta_0\n\\] a weighted average of the sample mean and the prior expectation: \\[\\begin{align*}\n\\theta_0 & =  \\frac{a}{a+b} ~~~~ \\rightarrow \\text{ prior expectation (or guess)} \\\\\nw & = a + b  ~~~~ \\rightarrow \\text{  prior confidence}\n\\end{align*}\\]"
  },
  {
    "objectID": "VB_Bayes1.html#example-a-non-bayesian-approach",
    "href": "VB_Bayes1.html#example-a-non-bayesian-approach",
    "title": "VectorByte Methods Training",
    "section": "Example: A non-Bayesian approach",
    "text": "Example: A non-Bayesian approach\nA standard estimate of a population proportion, \\(\\theta\\) is the sample mean \\(\\bar{y} = y/n\\). If \\(y=0 \\rightarrow \\bar{y} = 0\\).\n\nUnderstanding the sampling uncertainty is crucial (e.g., for reporting to health officials).\nThe most popular 95% confidence interval for a population proportion is the Wald Interval: \\[\n\\bar{y} \\pm 1.96 \\sqrt{\\bar{y}(1-\\bar{y})/n}.\n\\] This has the correct asymptotic coverage, but \\(y=0\\) is still problematic!"
  },
  {
    "objectID": "VB_Bayes1.html#conjugate-bayesian-models",
    "href": "VB_Bayes1.html#conjugate-bayesian-models",
    "title": "VectorByte Methods Training",
    "section": "Conjugate Bayesian Models",
    "text": "Conjugate Bayesian Models\nSome sets of priors/likelihoods/posteriors exhibit a special relationship called conjugacy: when posterior and prior distributions have the same form.\nE.g., in our Beta-Binomial/Bernoilli example: \\[\\begin{align*}\n\\theta & \\sim  \\mathrm{Beta} (a,b) \\\\\nY|\\theta &  \\sim  \\mathrm{Bin} (n, \\theta) \\\\\n\\theta | Y & \\sim  \\mathrm{Beta}(a^*, b^*)\n\\end{align*}\\]"
  },
  {
    "objectID": "VB_Bayes1.html#are-all-posteriors-in-the-same-family-as-the-priors-no",
    "href": "VB_Bayes1.html#are-all-posteriors-in-the-same-family-as-the-priors-no",
    "title": "VectorByte Methods Training",
    "section": "Are all posteriors in the same family as the priors? No",
    "text": "Are all posteriors in the same family as the priors? No\n\nConjugacy is a nice special property, but most of the time this isn’t the case.\n\nUsually getting an analytic form of the posterior distribution can be hard or impossible."
  },
  {
    "objectID": "VB_Bayes1.html#what-do-you-do-with-a-posterior",
    "href": "VB_Bayes1.html#what-do-you-do-with-a-posterior",
    "title": "VectorByte Methods Training",
    "section": "What do you do with a Posterior?",
    "text": "What do you do with a Posterior?\n\nSummarize important aspects of the posterior\n\nmean, median, mode, variance…\n\nCheck sensitivity of posterior to prior choice\nSay what range of parameters is consistent with the observed data given our prior information\nMake predictions"
  },
  {
    "objectID": "VB_Bayes1.html#posterior-summaries-point",
    "href": "VB_Bayes1.html#posterior-summaries-point",
    "title": "VectorByte Methods Training",
    "section": "Posterior Summaries (point)",
    "text": "Posterior Summaries (point)\nFor the Beta-Binomial model, we found that \\[\np(\\theta | y)= \\mathrm{Beta}(a+y, b+n-y).\n\\] We can calculate multiple summaries exactly, for example: \\[\\begin{align*}\n\\mathrm{mean}= \\mathrm{E}[\\theta|Y] & = \\frac{a+y}{a+b+n} \\\\\n\\mathrm{mode}(\\theta|Y) & = \\frac{a+y-1}{a+b+n-2} ~~~ \\dagger  \n\\end{align*}\\]\n \\(\\dagger\\) a.k.a. the maximum a posteriori estimator (MAP)"
  },
  {
    "objectID": "VB_Bayes1.html#prior-sensitivity",
    "href": "VB_Bayes1.html#prior-sensitivity",
    "title": "VectorByte Methods Training",
    "section": "Prior Sensitivity",
    "text": "Prior Sensitivity\nThe posterior expectation can be written as a weighted average of information from the prior and the data \\[\n\\mathrm{E}\\{\\theta |Y=y\\} =   \\frac{n}{a + b +n} \\bar{y} + \\frac{a+b}{a+b+n} \\theta_0.\n\\] Thus \\(a\\) and \\(b\\) can be interpreted here as prior data where \\(a\\) is the number of prior successes and \\(a+b\\) is the prior sample size. When \\(n\\gg a+b\\) most of our information comes from the data instead of the prior."
  },
  {
    "objectID": "VB_Bayes1.html#visualizing-the-prior-vs.-posterior",
    "href": "VB_Bayes1.html#visualizing-the-prior-vs.-posterior",
    "title": "VectorByte Methods Training",
    "section": "Visualizing the prior vs. posterior",
    "text": "Visualizing the prior vs. posterior\nWe can also visually check for sensitivity, since we don’t have general analytic approaches."
  },
  {
    "objectID": "VB_Bayes1.html#confidence-regions",
    "href": "VB_Bayes1.html#confidence-regions",
    "title": "VectorByte Methods Training",
    "section": "Confidence Regions",
    "text": "Confidence Regions\nAn interval \\([l(y), u(y)]\\), based on the observed data \\(Y=y\\), has 95 % Bayesian coverage for \\(\\theta\\) if \\[\nP(l(y) &lt;\\theta &lt; u(y)|Y=y)=0.95\n\\] The interpretation: it describes your information about the true value of \\(\\theta\\) after you have observed \\(Y=y\\).\n Such intervals are typically called credible intervals, to distinguish them from frequentist confidence intervals. Both are referred to as CIs."
  },
  {
    "objectID": "VB_Bayes1.html#quantile-based-bayesian-ci",
    "href": "VB_Bayes1.html#quantile-based-bayesian-ci",
    "title": "VectorByte Methods Training",
    "section": "Quantile-based (Bayesian) CI",
    "text": "Quantile-based (Bayesian) CI\nPerhaps the easiest way to obtain a credible interval is to use the posterior quantiles.\nTo make a \\(100 \\times (1-\\alpha)\\) % quantile-based CI, find numbers \\(\\theta_{\\alpha/2}&lt;\\theta_{1- \\alpha/2}\\) such that\n\n\\(P(\\theta &lt;\\theta_{\\alpha/2} |Y=y)=\\alpha/2\\)\n\\(P(\\theta &gt;\\theta_{1-\\alpha/2} |Y=y)=\\alpha/2\\)\n\nThe numbers \\(\\theta_{\\alpha/2},\\theta_{1- \\alpha/2}\\) are the \\(\\alpha/2\\) and \\(1-\\alpha/2\\) posterior quantiles of \\(\\theta\\)."
  },
  {
    "objectID": "VB_Bayes1.html#example-binomial-sampling-uniform-prior",
    "href": "VB_Bayes1.html#example-binomial-sampling-uniform-prior",
    "title": "VectorByte Methods Training",
    "section": "Example: Binomial sampling + uniform prior",
    "text": "Example: Binomial sampling + uniform prior\nSuppose out of \\(n=10\\) conditionally independent draws of a binary random variable we observe \\(Y=2\\) ones (successes).\n Using a uniform prior distribution (a.k.a., \\(\\mathrm{Beta}(1,1)\\)) for \\(\\theta\\), the posterior distribution is \\(\\theta | y=2 \\sim \\mathrm{Beta}(1+2,1+10-2)\\)."
  },
  {
    "objectID": "VB_Bayes1.html#alternative-hpd-region",
    "href": "VB_Bayes1.html#alternative-hpd-region",
    "title": "VectorByte Methods Training",
    "section": "Alternative: HPD region",
    "text": "Alternative: HPD region\nA \\(100 \\times(1-\\alpha)\\) % highest posterior density (HPD) regions is the part of parameter space, \\(s(y)\\), such that:\n\n\\(P(\\theta \\in s(y) |Y=y)= 1-\\alpha\\)\nIf \\(\\theta_a \\in s(y)\\) and \\(\\theta_b \\notin s(y)\\) then \\(P(\\theta_a |Y=y)&gt;P(\\theta_b |Y=y)\\)\n\n\\(\\Rightarrow\\) all points inside the HPD region have higher probability density than those outside."
  },
  {
    "objectID": "VB_Bayes1.html#next-steps",
    "href": "VB_Bayes1.html#next-steps",
    "title": "VectorByte Methods Training",
    "section": "Next Steps",
    "text": "Next Steps\nNext you’ll complete a practical where you conduct a conjugate Bayesian analysis for the mean of a normal distribution on the midge data introduced in the likelihood chapter. You’ll also visualize the effect of different prior choices on the posterior distribution."
  }
]